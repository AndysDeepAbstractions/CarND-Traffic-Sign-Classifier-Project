{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages, which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission if necessary. \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission. \n",
    "\n",
    "In addition to implementing code, there is a writeup to complete. The writeup should be completed in a separate file, which can be either a markdown file or a pdf document. There is a [write up template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) that can be used to guide the writing process. Completing the code template and writeup template will cover all of the [rubric points](https://review.udacity.com/#!/rubrics/481/view) for this project.\n",
    "\n",
    "The [rubric](https://review.udacity.com/#!/rubrics/481/view) contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this Ipython notebook and also discuss the results in the writeup file.\n",
    "\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'train.p'\n",
    "validation_file = 'valid.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test   = test['features'], test['labels']\n",
    "\n",
    "import numpy as np\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "\n",
    "    np.set_printoptions(threshold=np.nan)\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    \n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(range(43))\n",
    "    \n",
    "    x = encoder.transform(x)\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    x = x.astype(np.float32)\n",
    "    \n",
    "    return x\n",
    "\n",
    "y_train_idx = np.copy(y_train)\n",
    "y_valid_idx = np.copy(y_valid)\n",
    "y_test_idx  = np.copy(y_test)\n",
    "\n",
    "y_train = one_hot_encode(y_train)\n",
    "y_valid = one_hot_encode(y_valid)\n",
    "y_test  = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below. Use python, numpy and/or pandas methods to calculate the data summary rather than hard coding the results. For example, the [pandas shape method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html) might be useful for calculating some of the summary results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = X_train.shape[1:3]\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = y_train.shape[-1]\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualize the German Traffic Signs Dataset using the pickled file(s). This is open ended, suggestions include: plotting traffic sign images, plotting the count of each sign, etc.\n",
    "\n",
    "The [Matplotlib](http://matplotlib.org/) [examples](http://matplotlib.org/examples/index.html) and [gallery](http://matplotlib.org/gallery.html) pages are a great resource for doing visualizations in Python.\n",
    "\n",
    "**NOTE:** It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassId</th>\n",
       "      <th>SignName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Speed limit (20km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Speed limit (30km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Speed limit (50km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Speed limit (60km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Speed limit (70km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Speed limit (80km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>End of speed limit (80km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Speed limit (100km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Speed limit (120km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>No passing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>No passing for vehicles over 3.5 metric tons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Right-of-way at the next intersection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Priority road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Yield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>No vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Vehicles over 3.5 metric tons prohibited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>No entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>General caution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Dangerous curve to the left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Dangerous curve to the right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Double curve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Bumpy road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Slippery road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Road narrows on the right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Road work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Traffic signals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Pedestrians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Children crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Bicycles crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Beware of ice/snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Wild animals crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>End of all speed and passing limits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Turn right ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Turn left ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Ahead only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Go straight or right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Go straight or left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Keep right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Keep left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Roundabout mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>End of no passing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>End of no passing by vehicles over 3.5 metric ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ClassId                                           SignName\n",
       "0         0                               Speed limit (20km/h)\n",
       "1         1                               Speed limit (30km/h)\n",
       "2         2                               Speed limit (50km/h)\n",
       "3         3                               Speed limit (60km/h)\n",
       "4         4                               Speed limit (70km/h)\n",
       "5         5                               Speed limit (80km/h)\n",
       "6         6                        End of speed limit (80km/h)\n",
       "7         7                              Speed limit (100km/h)\n",
       "8         8                              Speed limit (120km/h)\n",
       "9         9                                         No passing\n",
       "10       10       No passing for vehicles over 3.5 metric tons\n",
       "11       11              Right-of-way at the next intersection\n",
       "12       12                                      Priority road\n",
       "13       13                                              Yield\n",
       "14       14                                               Stop\n",
       "15       15                                        No vehicles\n",
       "16       16           Vehicles over 3.5 metric tons prohibited\n",
       "17       17                                           No entry\n",
       "18       18                                    General caution\n",
       "19       19                        Dangerous curve to the left\n",
       "20       20                       Dangerous curve to the right\n",
       "21       21                                       Double curve\n",
       "22       22                                         Bumpy road\n",
       "23       23                                      Slippery road\n",
       "24       24                          Road narrows on the right\n",
       "25       25                                          Road work\n",
       "26       26                                    Traffic signals\n",
       "27       27                                        Pedestrians\n",
       "28       28                                  Children crossing\n",
       "29       29                                  Bicycles crossing\n",
       "30       30                                 Beware of ice/snow\n",
       "31       31                              Wild animals crossing\n",
       "32       32                End of all speed and passing limits\n",
       "33       33                                   Turn right ahead\n",
       "34       34                                    Turn left ahead\n",
       "35       35                                         Ahead only\n",
       "36       36                               Go straight or right\n",
       "37       37                                Go straight or left\n",
       "38       38                                         Keep right\n",
       "39       39                                          Keep left\n",
       "40       40                               Roundabout mandatory\n",
       "41       41                                  End of no passing\n",
       "42       42  End of no passing by vehicles over 3.5 metric ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./signnames.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFMr/A2oQYr/XbnhvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1838b3f0c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 41, Sign name: End of no passing\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUSgKfiEKRcEvRKEo+IUoFAW/EIXy/wGs63dbxxLMfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1838b837dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 4, Sign name: Speed limit (70km/h)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1838b8a6630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5, Sign name: Speed limit (80km/h)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1838b445b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 18, Sign name: General caution\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1838de4ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 12, Sign name: Priority road\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRcEvRKYo+IXIFAW/EJmi4BciU/4/e9lRyaKq3x4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1838deb5be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 25, Sign name: Road work\n"
     ]
    }
   ],
   "source": [
    "def visualise_dataset(X_train):\n",
    "    for i in range(0,X_train.shape[0],int(X_train.shape[0]/5)):  \n",
    "        image =  X_train[i,:,:,:]\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image)\n",
    "        plt.show()\n",
    "        sign_id = y_train_idx[i]\n",
    "        sign_name = df.values[sign_id,-1]\n",
    "        print('ID: {}, Sign name: {}'.format(sign_id,sign_name))\n",
    "        \n",
    "visualise_dataset(X_train)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play! \n",
    "\n",
    "With the LeNet-5 solution from the lecture, you should expect a validation set accuracy of about 0.89. To meet specifications, the validation set accuracy will need to be at least 0.93. It is possible to get an even higher accuracy, but 0.93 is the minimum for a successful project submission. \n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 32, 32, 3)\n",
      "(4410, 32, 32, 3)\n",
      "(12630, 32, 32, 3)\n",
      "[28 25 24]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train[0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.83 s\n",
      "Wall time: 1.42 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def conv_to_concat_colorspace(image_batch):\n",
    "    shape = np.asarray(image_batch.shape)\n",
    "    shape[-1] *= 2\n",
    "    concat_batch = np.empty(shape)\n",
    "    for idx in range(image_batch.shape[0]):\n",
    "        concat_batch[idx,:,:,0:3] = cv2.cvtColor(image_batch[idx], cv2.COLOR_RGB2HLS)\n",
    "        concat_batch[idx,:,:,3:6] = image_batch[idx]\n",
    "        concat_batch[idx,:,:,:]   =  concat_batch[idx,:,:,:]/255\n",
    "    return concat_batch\n",
    "\n",
    "%time X_train_ = conv_to_concat_colorspace(X_train)\n",
    "%time X_valid_ = conv_to_concat_colorspace(X_valid)\n",
    "%time X_test_  = conv_to_concat_colorspace(X_test)\n",
    "\n",
    "X_train = X_train_\n",
    "X_valid = X_valid_ \n",
    "X_test  = X_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open('X_train.pickle', 'rb') as handle:\n",
    "        X_train = pickle.load(handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('X_valid.pickle', 'rb') as handle:\n",
    "        X_valid = pickle.load(handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('X_test.pickle', 'rb') as handle:\n",
    "        X_test = pickle.load(handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "if False:\n",
    "    with open('X_train.pickle', 'wb') as handle:\n",
    "        pickle.dump(X_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('X_valid.pickle', 'wb') as handle:\n",
    "        pickle.dump(X_valid, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('X_test.pickle', 'wb') as handle:\n",
    "        pickle.dump(X_test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 32, 32, 6)\n",
      "(4410, 32, 32, 6)\n",
      "(12630, 32, 32, 6)\n",
      "[ 0.03137255  0.10196078  0.07843137  0.10980392  0.09803922  0.09411765]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train[0,0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the weight and bias\n",
    "    biases  = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    # TF 1.0 :\n",
    "    #weights_depth = x_tensor.shape.as_list()[-1]\n",
    "    # TF 0.12 :\n",
    "    weights_depth = x_tensor.get_shape().as_list()[-1]\n",
    "\n",
    "    \n",
    "    weights_dim = [conv_ksize[0], conv_ksize[1], weights_depth, conv_num_outputs]\n",
    "\n",
    "    #print((x_tensor.shape))\n",
    "    #print(weights_dim)\n",
    "    weights = tf.Variable(tf.truncated_normal(weights_dim))\n",
    "    \n",
    "    # Apply Convolution\n",
    "    conv_strides = [1, conv_strides[0], conv_strides[1], 1] # (batch, height, width, depth)\n",
    "    padding = 'SAME'\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weights, conv_strides, padding)\n",
    "\n",
    "    # Add bias\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, biases)\n",
    "    \n",
    "    # Apply activation function\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    filter_shape = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    pool_strides = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    padding = 'VALID'\n",
    "    pool = tf.nn.max_pool(conv_layer, filter_shape, pool_strides, padding)\n",
    "    \n",
    "    return pool \n",
    "\n",
    "\n",
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    dimensions = (x_tensor.get_shape().as_list()[1:4])\n",
    "    \n",
    "    prod = 1\n",
    "    for dimension in dimensions:\n",
    "        prod *= dimension\n",
    "    \n",
    "    x_tensor = tf.reshape(x_tensor, [-1,prod])\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    tensor_out = tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "    return tensor_out\n",
    "\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    x_tensor = x         #:param x_tensor: TensorFlow Tensor\n",
    "    conv_num_outputs = 4 #:param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    conv_strides = (1,1) #:param conv_strides: Stride 2-D Tuple for convolution\n",
    "    pool_ksize = (2,2)   #:param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    pool_strides = (1,1) #:param pool_strides: Stride 2-D Tuple for pool\n",
    "    conv_ksize = (3,3)\n",
    "    x_tensor = conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_num_outputs = 8 #:param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    x_tensor = conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_num_outputs = 16 #:param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    x_tensor = conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    # Function Definition from Above:\n",
    "    #   \n",
    "    x_tensor = flatten(x_tensor)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   \n",
    "    num_outputs = n_classes*4\n",
    "    x_tensor = fully_conn(x_tensor, int(num_outputs))\n",
    "    x_tensor = tf.nn.dropout(x_tensor, keep_prob)\n",
    "    num_outputs = n_classes*3\n",
    "    x_tensor = fully_conn(x_tensor, int(num_outputs))\n",
    "    x_tensor = tf.nn.dropout(x_tensor, keep_prob)\n",
    "    num_outputs = n_classes*2\n",
    "    x_tensor = tf.nn.dropout(x_tensor, keep_prob)\n",
    "    x_tensor = fully_conn(x_tensor, int(num_outputs))\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   \n",
    "    num_outputs = n_classes\n",
    "    x_tensor = fully_conn(x_tensor, int(num_outputs))\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "image_shape = X_train.shape[1:]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2]],name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes],name = 'y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch    1, Batch_idx    0:  Loss:  57.38760 Validation Accuracy:   0.03906\n",
      "Epoch    1, Batch_idx  128:  Loss:  34.63283 Validation Accuracy:   0.06250\n",
      "Epoch    1, Batch_idx  256:  Loss:  23.91308 Validation Accuracy:   0.07812\n",
      "Epoch    2, Batch_idx    0:  Loss:  20.24387 Validation Accuracy:   0.04688\n",
      "Epoch    2, Batch_idx  128:  Loss:  18.68010 Validation Accuracy:   0.04688\n",
      "Epoch    2, Batch_idx  256:  Loss:  12.60949 Validation Accuracy:   0.03125\n",
      "Epoch    3, Batch_idx    0:  Loss:  14.01137 Validation Accuracy:   0.00000\n",
      "Epoch    3, Batch_idx  128:  Loss:  13.67545 Validation Accuracy:   0.07812\n",
      "Epoch    3, Batch_idx  256:  Loss:   7.02064 Validation Accuracy:   0.04688\n",
      "Epoch    4, Batch_idx    0:  Loss:   7.04662 Validation Accuracy:   0.03125\n",
      "Epoch    4, Batch_idx  128:  Loss:   7.40180 Validation Accuracy:   0.03125\n",
      "Epoch    4, Batch_idx  256:  Loss:   5.64924 Validation Accuracy:   0.07031\n",
      "Epoch    5, Batch_idx    0:  Loss:   5.38751 Validation Accuracy:   0.03125\n",
      "Epoch    5, Batch_idx  128:  Loss:   5.36370 Validation Accuracy:   0.02344\n",
      "Epoch    5, Batch_idx  256:  Loss:   4.62799 Validation Accuracy:   0.02344\n",
      "Epoch    6, Batch_idx    0:  Loss:   4.56137 Validation Accuracy:   0.06250\n",
      "Epoch    6, Batch_idx  128:  Loss:   4.24549 Validation Accuracy:   0.03125\n",
      "Epoch    6, Batch_idx  256:  Loss:   4.08055 Validation Accuracy:   0.00781\n",
      "Epoch    7, Batch_idx    0:  Loss:   3.67718 Validation Accuracy:   0.10156\n",
      "Epoch    7, Batch_idx  128:  Loss:   3.78017 Validation Accuracy:   0.05469\n",
      "Epoch    7, Batch_idx  256:  Loss:   3.77127 Validation Accuracy:   0.05469\n",
      "Epoch    8, Batch_idx    0:  Loss:   3.74943 Validation Accuracy:   0.05469\n",
      "Epoch    8, Batch_idx  128:  Loss:   3.75722 Validation Accuracy:   0.07812\n",
      "Epoch    8, Batch_idx  256:  Loss:   3.73388 Validation Accuracy:   0.04688\n",
      "Epoch    9, Batch_idx    0:  Loss:   3.72891 Validation Accuracy:   0.00781\n",
      "Epoch    9, Batch_idx  128:  Loss:   3.71390 Validation Accuracy:   0.01562\n",
      "Epoch    9, Batch_idx  256:  Loss:   3.70767 Validation Accuracy:   0.02344\n",
      "Epoch   10, Batch_idx    0:  Loss:   3.66275 Validation Accuracy:   0.01562\n",
      "Epoch   10, Batch_idx  128:  Loss:   3.64697 Validation Accuracy:   0.01562\n",
      "Epoch   10, Batch_idx  256:  Loss:   3.63980 Validation Accuracy:   0.04688\n",
      "Epoch   11, Batch_idx    0:  Loss:   3.73847 Validation Accuracy:   0.02344\n",
      "Epoch   11, Batch_idx  128:  Loss:   3.72854 Validation Accuracy:   0.01562\n",
      "Epoch   11, Batch_idx  256:  Loss:   3.71549 Validation Accuracy:   0.01562\n",
      "Epoch   12, Batch_idx    0:  Loss:   3.65671 Validation Accuracy:   0.05469\n",
      "Epoch   12, Batch_idx  128:  Loss:   3.62651 Validation Accuracy:   0.05469\n",
      "Epoch   12, Batch_idx  256:  Loss:   3.61392 Validation Accuracy:   0.06250\n",
      "Epoch   13, Batch_idx    0:  Loss:   3.64658 Validation Accuracy:   0.07031\n",
      "Epoch   13, Batch_idx  128:  Loss:   3.62710 Validation Accuracy:   0.07812\n",
      "Epoch   13, Batch_idx  256:  Loss:   3.61489 Validation Accuracy:   0.08594\n",
      "Epoch   14, Batch_idx    0:  Loss:   3.70327 Validation Accuracy:   0.04688\n",
      "Epoch   14, Batch_idx  128:  Loss:   3.71871 Validation Accuracy:   0.04688\n",
      "Epoch   14, Batch_idx  256:  Loss:   3.71994 Validation Accuracy:   0.03906\n",
      "Epoch   15, Batch_idx    0:  Loss:   3.68776 Validation Accuracy:   0.10938\n",
      "Epoch   15, Batch_idx  128:  Loss:   3.66017 Validation Accuracy:   0.11719\n",
      "Epoch   15, Batch_idx  256:  Loss:   3.60684 Validation Accuracy:   0.14062\n",
      "Epoch   16, Batch_idx    0:  Loss:   3.67171 Validation Accuracy:   0.06250\n",
      "Epoch   16, Batch_idx  128:  Loss:   3.67853 Validation Accuracy:   0.07031\n",
      "Epoch   16, Batch_idx  256:  Loss:   3.65941 Validation Accuracy:   0.06250\n",
      "Epoch   17, Batch_idx    0:  Loss:   3.61965 Validation Accuracy:   0.07812\n",
      "Epoch   17, Batch_idx  128:  Loss:   3.63482 Validation Accuracy:   0.07812\n",
      "Epoch   17, Batch_idx  256:  Loss:   3.63722 Validation Accuracy:   0.06250\n",
      "Epoch   18, Batch_idx    0:  Loss:   3.63849 Validation Accuracy:   0.08594\n",
      "Epoch   18, Batch_idx  128:  Loss:   3.62709 Validation Accuracy:   0.10156\n",
      "Epoch   18, Batch_idx  256:  Loss:   3.61864 Validation Accuracy:   0.11719\n",
      "Epoch   19, Batch_idx    0:  Loss:   3.65918 Validation Accuracy:   0.03906\n",
      "Epoch   19, Batch_idx  128:  Loss:   3.64033 Validation Accuracy:   0.05469\n",
      "Epoch   19, Batch_idx  256:  Loss:   3.62428 Validation Accuracy:   0.06250\n",
      "Epoch   20, Batch_idx    0:  Loss:   3.62821 Validation Accuracy:   0.09375\n",
      "Epoch   20, Batch_idx  128:  Loss:   3.62491 Validation Accuracy:   0.09375\n",
      "Epoch   20, Batch_idx  256:  Loss:   3.60648 Validation Accuracy:   0.09375\n",
      "Epoch   21, Batch_idx    0:  Loss:   3.57854 Validation Accuracy:   0.07031\n",
      "Epoch   21, Batch_idx  128:  Loss:   3.55984 Validation Accuracy:   0.07812\n",
      "Epoch   21, Batch_idx  256:  Loss:   3.55910 Validation Accuracy:   0.06250\n",
      "Epoch   22, Batch_idx    0:  Loss:   3.57017 Validation Accuracy:   0.09375\n",
      "Epoch   22, Batch_idx  128:  Loss:   3.57559 Validation Accuracy:   0.08594\n",
      "Epoch   22, Batch_idx  256:  Loss:   3.56554 Validation Accuracy:   0.09375\n",
      "Epoch   23, Batch_idx    0:  Loss:   3.46455 Validation Accuracy:   0.10938\n",
      "Epoch   23, Batch_idx  128:  Loss:   3.44152 Validation Accuracy:   0.09375\n",
      "Epoch   23, Batch_idx  256:  Loss:   3.44294 Validation Accuracy:   0.07812\n",
      "Epoch   24, Batch_idx    0:  Loss:   3.48127 Validation Accuracy:   0.11719\n",
      "Epoch   24, Batch_idx  128:  Loss:   3.48293 Validation Accuracy:   0.15625\n",
      "Epoch   24, Batch_idx  256:  Loss:   3.45506 Validation Accuracy:   0.15625\n",
      "Epoch   25, Batch_idx    0:  Loss:   3.62481 Validation Accuracy:   0.08594\n",
      "Epoch   25, Batch_idx  128:  Loss:   3.59665 Validation Accuracy:   0.06250\n",
      "Epoch   25, Batch_idx  256:  Loss:   3.58063 Validation Accuracy:   0.06250\n",
      "Epoch   26, Batch_idx    0:  Loss:   3.52666 Validation Accuracy:   0.11719\n",
      "Epoch   26, Batch_idx  128:  Loss:   3.53475 Validation Accuracy:   0.12500\n",
      "Epoch   26, Batch_idx  256:  Loss:   3.51983 Validation Accuracy:   0.12500\n",
      "Epoch   27, Batch_idx    0:  Loss:   3.48980 Validation Accuracy:   0.09375\n",
      "Epoch   27, Batch_idx  128:  Loss:   3.44885 Validation Accuracy:   0.08594\n",
      "Epoch   27, Batch_idx  256:  Loss:   3.41653 Validation Accuracy:   0.09375\n",
      "Epoch   28, Batch_idx    0:  Loss:   3.44385 Validation Accuracy:   0.10938\n",
      "Epoch   28, Batch_idx  128:  Loss:   3.42397 Validation Accuracy:   0.11719\n",
      "Epoch   28, Batch_idx  256:  Loss:   3.44072 Validation Accuracy:   0.12500\n",
      "Epoch   29, Batch_idx    0:  Loss:   3.42451 Validation Accuracy:   0.11719\n",
      "Epoch   29, Batch_idx  128:  Loss:   3.41352 Validation Accuracy:   0.10938\n",
      "Epoch   29, Batch_idx  256:  Loss:   3.40062 Validation Accuracy:   0.11719\n",
      "Epoch   30, Batch_idx    0:  Loss:   3.44423 Validation Accuracy:   0.15625\n",
      "Epoch   30, Batch_idx  128:  Loss:   3.46609 Validation Accuracy:   0.14844\n",
      "Epoch   30, Batch_idx  256:  Loss:   3.41144 Validation Accuracy:   0.14844\n",
      "Epoch   31, Batch_idx    0:  Loss:   3.45131 Validation Accuracy:   0.11719\n",
      "Epoch   31, Batch_idx  128:  Loss:   3.43926 Validation Accuracy:   0.13281\n",
      "Epoch   31, Batch_idx  256:  Loss:   3.42679 Validation Accuracy:   0.12500\n",
      "Epoch   32, Batch_idx    0:  Loss:   3.33340 Validation Accuracy:   0.14062\n",
      "Epoch   32, Batch_idx  128:  Loss:   3.32051 Validation Accuracy:   0.14844\n",
      "Epoch   32, Batch_idx  256:  Loss:   3.31164 Validation Accuracy:   0.17188\n",
      "Epoch   33, Batch_idx    0:  Loss:   3.39410 Validation Accuracy:   0.10156\n",
      "Epoch   33, Batch_idx  128:  Loss:   3.38786 Validation Accuracy:   0.12500\n",
      "Epoch   33, Batch_idx  256:  Loss:   3.39032 Validation Accuracy:   0.10938\n",
      "Epoch   34, Batch_idx    0:  Loss:   3.51136 Validation Accuracy:   0.10938\n",
      "Epoch   34, Batch_idx  128:  Loss:   3.47210 Validation Accuracy:   0.09375\n",
      "Epoch   34, Batch_idx  256:  Loss:   3.46898 Validation Accuracy:   0.08594\n",
      "Epoch   35, Batch_idx    0:  Loss:   3.35566 Validation Accuracy:   0.10938\n",
      "Epoch   35, Batch_idx  128:  Loss:   3.31473 Validation Accuracy:   0.10156\n",
      "Epoch   35, Batch_idx  256:  Loss:   3.32641 Validation Accuracy:   0.10156\n",
      "Epoch   36, Batch_idx    0:  Loss:   3.47204 Validation Accuracy:   0.14844\n",
      "Epoch   36, Batch_idx  128:  Loss:   3.45805 Validation Accuracy:   0.14062\n",
      "Epoch   36, Batch_idx  256:  Loss:   3.48226 Validation Accuracy:   0.10938\n",
      "Epoch   37, Batch_idx    0:  Loss:   3.33101 Validation Accuracy:   0.14062\n",
      "Epoch   37, Batch_idx  128:  Loss:   3.37512 Validation Accuracy:   0.13281\n",
      "Epoch   37, Batch_idx  256:  Loss:   3.36951 Validation Accuracy:   0.12500\n",
      "Epoch   38, Batch_idx    0:  Loss:   3.48894 Validation Accuracy:   0.07031\n",
      "Epoch   38, Batch_idx  128:  Loss:   3.48081 Validation Accuracy:   0.07031\n",
      "Epoch   38, Batch_idx  256:  Loss:   3.47203 Validation Accuracy:   0.07031\n",
      "Epoch   39, Batch_idx    0:  Loss:   3.51788 Validation Accuracy:   0.08594\n",
      "Epoch   39, Batch_idx  128:  Loss:   3.50265 Validation Accuracy:   0.08594\n",
      "Epoch   39, Batch_idx  256:  Loss:   3.43982 Validation Accuracy:   0.06250\n",
      "Epoch   40, Batch_idx    0:  Loss:   3.54290 Validation Accuracy:   0.05469\n",
      "Epoch   40, Batch_idx  128:  Loss:   3.52054 Validation Accuracy:   0.06250\n",
      "Epoch   40, Batch_idx  256:  Loss:   3.51704 Validation Accuracy:   0.10156\n",
      "Epoch   41, Batch_idx    0:  Loss:   3.38171 Validation Accuracy:   0.16406\n",
      "Epoch   41, Batch_idx  128:  Loss:   3.33776 Validation Accuracy:   0.17188\n",
      "Epoch   41, Batch_idx  256:  Loss:   3.29865 Validation Accuracy:   0.15625\n",
      "Epoch   42, Batch_idx    0:  Loss:   3.37272 Validation Accuracy:   0.10938\n",
      "Epoch   42, Batch_idx  128:  Loss:   3.36285 Validation Accuracy:   0.10156\n",
      "Epoch   42, Batch_idx  256:  Loss:   3.33619 Validation Accuracy:   0.09375\n",
      "Epoch   43, Batch_idx    0:  Loss:   3.40768 Validation Accuracy:   0.14062\n",
      "Epoch   43, Batch_idx  128:  Loss:   3.43037 Validation Accuracy:   0.13281\n",
      "Epoch   43, Batch_idx  256:  Loss:   3.40824 Validation Accuracy:   0.10938\n",
      "Epoch   44, Batch_idx    0:  Loss:   3.22481 Validation Accuracy:   0.14062\n",
      "Epoch   44, Batch_idx  128:  Loss:   3.39707 Validation Accuracy:   0.09375\n",
      "Epoch   44, Batch_idx  256:  Loss:   3.25377 Validation Accuracy:   0.16406\n",
      "Epoch   45, Batch_idx    0:  Loss:   3.50131 Validation Accuracy:   0.16406\n",
      "Epoch   45, Batch_idx  128:  Loss:   3.50543 Validation Accuracy:   0.14062\n",
      "Epoch   45, Batch_idx  256:  Loss:   3.50337 Validation Accuracy:   0.13281\n",
      "Epoch   46, Batch_idx    0:  Loss:   3.53517 Validation Accuracy:   0.08594\n",
      "Epoch   46, Batch_idx  128:  Loss:   3.54193 Validation Accuracy:   0.08594\n",
      "Epoch   46, Batch_idx  256:  Loss:   3.54287 Validation Accuracy:   0.09375\n",
      "Epoch   47, Batch_idx    0:  Loss:   3.64201 Validation Accuracy:   0.06250\n",
      "Epoch   47, Batch_idx  128:  Loss:   3.63451 Validation Accuracy:   0.07031\n",
      "Epoch   47, Batch_idx  256:  Loss:   3.62308 Validation Accuracy:   0.08594\n",
      "Epoch   48, Batch_idx    0:  Loss:   3.52281 Validation Accuracy:   0.08594\n",
      "Epoch   48, Batch_idx  128:  Loss:   3.51025 Validation Accuracy:   0.10156\n",
      "Epoch   48, Batch_idx  256:  Loss:   3.50204 Validation Accuracy:   0.10938\n",
      "Epoch   49, Batch_idx    0:  Loss:   3.56098 Validation Accuracy:   0.09375\n",
      "Epoch   49, Batch_idx  128:  Loss:   3.55137 Validation Accuracy:   0.09375\n",
      "Epoch   49, Batch_idx  256:  Loss:   3.53399 Validation Accuracy:   0.10938\n",
      "Epoch   50, Batch_idx    0:  Loss:   3.59621 Validation Accuracy:   0.12500\n",
      "Epoch   50, Batch_idx  128:  Loss:   3.58462 Validation Accuracy:   0.11719\n",
      "Epoch   50, Batch_idx  256:  Loss:   3.57251 Validation Accuracy:   0.11719\n",
      "Epoch   51, Batch_idx    0:  Loss:   3.54541 Validation Accuracy:   0.09375\n",
      "Epoch   51, Batch_idx  128:  Loss:   4.46712 Validation Accuracy:   0.08594\n",
      "Epoch   51, Batch_idx  256:  Loss:   3.51637 Validation Accuracy:   0.09375\n",
      "Epoch   52, Batch_idx    0:  Loss:   3.51221 Validation Accuracy:   0.10156\n",
      "Epoch   52, Batch_idx  128:  Loss:   3.49924 Validation Accuracy:   0.09375\n",
      "Epoch   52, Batch_idx  256:  Loss:   3.48584 Validation Accuracy:   0.09375\n",
      "Epoch   53, Batch_idx    0:  Loss:   3.38421 Validation Accuracy:   0.12500\n",
      "Epoch   53, Batch_idx  128:  Loss:   3.36894 Validation Accuracy:   0.11719\n",
      "Epoch   53, Batch_idx  256:  Loss:   3.34980 Validation Accuracy:   0.12500\n",
      "Epoch   54, Batch_idx    0:  Loss:   3.51922 Validation Accuracy:   0.12500\n",
      "Epoch   54, Batch_idx  128:  Loss:   3.50697 Validation Accuracy:   0.12500\n",
      "Epoch   54, Batch_idx  256:  Loss:   3.49815 Validation Accuracy:   0.12500\n",
      "Epoch   55, Batch_idx    0:  Loss:   3.48700 Validation Accuracy:   0.11719\n",
      "Epoch   55, Batch_idx  128:  Loss:   3.50131 Validation Accuracy:   0.10156\n",
      "Epoch   55, Batch_idx  256:  Loss:   3.50222 Validation Accuracy:   0.10938\n",
      "Epoch   56, Batch_idx    0:  Loss:   3.49777 Validation Accuracy:   0.12500\n",
      "Epoch   56, Batch_idx  128:  Loss:   3.45711 Validation Accuracy:   0.13281\n",
      "Epoch   56, Batch_idx  256:  Loss:   3.45455 Validation Accuracy:   0.12500\n",
      "Epoch   57, Batch_idx    0:  Loss:   3.45076 Validation Accuracy:   0.10938\n",
      "Epoch   57, Batch_idx  128:  Loss:   3.47159 Validation Accuracy:   0.13281\n",
      "Epoch   57, Batch_idx  256:  Loss:   3.48222 Validation Accuracy:   0.14062\n",
      "Epoch   58, Batch_idx    0:  Loss:   3.45003 Validation Accuracy:   0.12500\n",
      "Epoch   58, Batch_idx  128:  Loss:   3.37592 Validation Accuracy:   0.11719\n",
      "Epoch   58, Batch_idx  256:  Loss:   3.38538 Validation Accuracy:   0.09375\n",
      "Epoch   59, Batch_idx    0:  Loss:   3.60480 Validation Accuracy:   0.07812\n",
      "Epoch   59, Batch_idx  128:  Loss:   3.63872 Validation Accuracy:   0.04688\n",
      "Epoch   59, Batch_idx  256:  Loss:   3.64159 Validation Accuracy:   0.03906\n",
      "Epoch   60, Batch_idx    0:  Loss:   3.51425 Validation Accuracy:   0.07031\n",
      "Epoch   60, Batch_idx  128:  Loss:   3.51707 Validation Accuracy:   0.07031\n",
      "Epoch   60, Batch_idx  256:  Loss:   3.50646 Validation Accuracy:   0.06250\n",
      "Epoch   61, Batch_idx    0:  Loss:   3.47081 Validation Accuracy:   0.11719\n",
      "Epoch   61, Batch_idx  128:  Loss:   3.46050 Validation Accuracy:   0.11719\n",
      "Epoch   61, Batch_idx  256:  Loss:   3.44412 Validation Accuracy:   0.11719\n",
      "Epoch   62, Batch_idx    0:  Loss:   3.56299 Validation Accuracy:   0.10156\n",
      "Epoch   62, Batch_idx  128:  Loss:   3.54882 Validation Accuracy:   0.10938\n",
      "Epoch   62, Batch_idx  256:  Loss:   3.53611 Validation Accuracy:   0.09375\n",
      "Epoch   63, Batch_idx    0:  Loss:   3.39841 Validation Accuracy:   0.15625\n",
      "Epoch   63, Batch_idx  128:  Loss:   3.37554 Validation Accuracy:   0.14844\n",
      "Epoch   63, Batch_idx  256:  Loss:   3.35600 Validation Accuracy:   0.13281\n",
      "Epoch   64, Batch_idx    0:  Loss:   3.41884 Validation Accuracy:   0.10156\n",
      "Epoch   64, Batch_idx  128:  Loss:   3.36590 Validation Accuracy:   0.12500\n",
      "Epoch   64, Batch_idx  256:  Loss:   3.42277 Validation Accuracy:   0.12500\n",
      "Epoch   65, Batch_idx    0:  Loss:   3.31367 Validation Accuracy:   0.17188\n",
      "Epoch   65, Batch_idx  128:  Loss:   3.32486 Validation Accuracy:   0.17188\n",
      "Epoch   65, Batch_idx  256:  Loss:   3.32078 Validation Accuracy:   0.18750\n",
      "Epoch   66, Batch_idx    0:  Loss:   3.39909 Validation Accuracy:   0.13281\n",
      "Epoch   66, Batch_idx  128:  Loss:   3.38068 Validation Accuracy:   0.13281\n",
      "Epoch   66, Batch_idx  256:  Loss:   3.35439 Validation Accuracy:   0.14062\n",
      "Epoch   67, Batch_idx    0:  Loss:   3.46674 Validation Accuracy:   0.10156\n",
      "Epoch   67, Batch_idx  128:  Loss:   3.43848 Validation Accuracy:   0.08594\n",
      "Epoch   67, Batch_idx  256:  Loss:   3.41128 Validation Accuracy:   0.10156\n",
      "Epoch   68, Batch_idx    0:  Loss:   3.32883 Validation Accuracy:   0.11719\n",
      "Epoch   68, Batch_idx  128:  Loss:   3.27354 Validation Accuracy:   0.11719\n",
      "Epoch   68, Batch_idx  256:  Loss:   3.30986 Validation Accuracy:   0.14844\n",
      "Epoch   69, Batch_idx    0:  Loss:   3.48409 Validation Accuracy:   0.11719\n",
      "Epoch   69, Batch_idx  128:  Loss:   3.51206 Validation Accuracy:   0.11719\n",
      "Epoch   69, Batch_idx  256:  Loss:   3.52369 Validation Accuracy:   0.10156\n",
      "Epoch   70, Batch_idx    0:  Loss:   3.54804 Validation Accuracy:   0.08594\n",
      "Epoch   70, Batch_idx  128:  Loss:   3.55162 Validation Accuracy:   0.08594\n",
      "Epoch   70, Batch_idx  256:  Loss:   3.53560 Validation Accuracy:   0.10156\n",
      "Epoch   71, Batch_idx    0:  Loss:   3.54065 Validation Accuracy:   0.07031\n",
      "Epoch   71, Batch_idx  128:  Loss:   3.53256 Validation Accuracy:   0.07812\n",
      "Epoch   71, Batch_idx  256:  Loss:   3.52119 Validation Accuracy:   0.08594\n",
      "Epoch   72, Batch_idx    0:  Loss:   3.43880 Validation Accuracy:   0.14844\n",
      "Epoch   72, Batch_idx  128:  Loss:   3.42525 Validation Accuracy:   0.14844\n",
      "Epoch   72, Batch_idx  256:  Loss:   3.40678 Validation Accuracy:   0.14844\n",
      "Epoch   73, Batch_idx    0:  Loss:   3.35842 Validation Accuracy:   0.10938\n",
      "Epoch   73, Batch_idx  128:  Loss:   3.33357 Validation Accuracy:   0.10938\n",
      "Epoch   73, Batch_idx  256:  Loss:   3.30455 Validation Accuracy:   0.10938\n",
      "Epoch   74, Batch_idx    0:  Loss:   3.33405 Validation Accuracy:   0.13281\n",
      "Epoch   74, Batch_idx  128:  Loss:   3.31110 Validation Accuracy:   0.14062\n",
      "Epoch   74, Batch_idx  256:  Loss:   3.30708 Validation Accuracy:   0.14844\n",
      "Epoch   75, Batch_idx    0:  Loss:   3.42781 Validation Accuracy:   0.10938\n",
      "Epoch   75, Batch_idx  128:  Loss:   3.44668 Validation Accuracy:   0.10938\n",
      "Epoch   75, Batch_idx  256:  Loss:   3.45802 Validation Accuracy:   0.11719\n",
      "Epoch   76, Batch_idx    0:  Loss:   3.39760 Validation Accuracy:   0.11719\n",
      "Epoch   76, Batch_idx  128:  Loss:   3.39537 Validation Accuracy:   0.11719\n",
      "Epoch   76, Batch_idx  256:  Loss:   3.38467 Validation Accuracy:   0.11719\n",
      "Epoch   77, Batch_idx    0:  Loss:   3.35710 Validation Accuracy:   0.14844\n",
      "Epoch   77, Batch_idx  128:  Loss:   3.32486 Validation Accuracy:   0.14844\n",
      "Epoch   77, Batch_idx  256:  Loss:   3.28786 Validation Accuracy:   0.15625\n",
      "Epoch   78, Batch_idx    0:  Loss:   3.35797 Validation Accuracy:   0.12500\n",
      "Epoch   78, Batch_idx  128:  Loss:   3.33596 Validation Accuracy:   0.14062\n",
      "Epoch   78, Batch_idx  256:  Loss:   3.32668 Validation Accuracy:   0.15625\n",
      "Epoch   79, Batch_idx    0:  Loss:   3.35500 Validation Accuracy:   0.12500\n",
      "Epoch   79, Batch_idx  128:  Loss:   3.34487 Validation Accuracy:   0.15625\n",
      "Epoch   79, Batch_idx  256:  Loss:   3.36651 Validation Accuracy:   0.16406\n",
      "Epoch   80, Batch_idx    0:  Loss:   3.31045 Validation Accuracy:   0.12500\n",
      "Epoch   80, Batch_idx  128:  Loss:   3.31126 Validation Accuracy:   0.15625\n",
      "Epoch   80, Batch_idx  256:  Loss:   3.29716 Validation Accuracy:   0.16406\n",
      "Epoch   81, Batch_idx    0:  Loss:   3.50787 Validation Accuracy:   0.10938\n",
      "Epoch   81, Batch_idx  128:  Loss:   3.48301 Validation Accuracy:   0.08594\n",
      "Epoch   81, Batch_idx  256:  Loss:   3.45944 Validation Accuracy:   0.09375\n",
      "Epoch   82, Batch_idx    0:  Loss:   3.35200 Validation Accuracy:   0.10156\n",
      "Epoch   82, Batch_idx  128:  Loss:   3.33406 Validation Accuracy:   0.10938\n",
      "Epoch   82, Batch_idx  256:  Loss:   3.27935 Validation Accuracy:   0.11719\n",
      "Epoch   83, Batch_idx    0:  Loss:   3.17621 Validation Accuracy:   0.14844\n",
      "Epoch   83, Batch_idx  128:  Loss:   3.19958 Validation Accuracy:   0.16406\n",
      "Epoch   83, Batch_idx  256:  Loss:   3.21148 Validation Accuracy:   0.14844\n",
      "Epoch   84, Batch_idx    0:  Loss:   3.46795 Validation Accuracy:   0.10938\n",
      "Epoch   84, Batch_idx  128:  Loss:   3.43693 Validation Accuracy:   0.10938\n",
      "Epoch   84, Batch_idx  256:  Loss:   3.42538 Validation Accuracy:   0.10156\n",
      "Epoch   85, Batch_idx    0:  Loss:   3.29814 Validation Accuracy:   0.11719\n",
      "Epoch   85, Batch_idx  128:  Loss:   3.29132 Validation Accuracy:   0.11719\n",
      "Epoch   85, Batch_idx  256:  Loss:   3.25418 Validation Accuracy:   0.11719\n",
      "Epoch   86, Batch_idx    0:  Loss:   3.29685 Validation Accuracy:   0.13281\n",
      "Epoch   86, Batch_idx  128:  Loss:   3.28352 Validation Accuracy:   0.13281\n",
      "Epoch   86, Batch_idx  256:  Loss:   3.26985 Validation Accuracy:   0.14062\n",
      "Epoch   87, Batch_idx    0:  Loss:   3.26546 Validation Accuracy:   0.17188\n",
      "Epoch   87, Batch_idx  128:  Loss:   3.26487 Validation Accuracy:   0.19531\n",
      "Epoch   87, Batch_idx  256:  Loss:   3.26229 Validation Accuracy:   0.20312\n",
      "Epoch   88, Batch_idx    0:  Loss:   3.24879 Validation Accuracy:   0.16406\n",
      "Epoch   88, Batch_idx  128:  Loss:   3.24329 Validation Accuracy:   0.16406\n",
      "Epoch   88, Batch_idx  256:  Loss:   3.23235 Validation Accuracy:   0.15625\n",
      "Epoch   89, Batch_idx    0:  Loss:   3.08876 Validation Accuracy:   0.17188\n",
      "Epoch   89, Batch_idx  128:  Loss:   3.05614 Validation Accuracy:   0.17188\n",
      "Epoch   89, Batch_idx  256:  Loss:   3.02139 Validation Accuracy:   0.17969\n",
      "Epoch   90, Batch_idx    0:  Loss:   3.25919 Validation Accuracy:   0.14844\n",
      "Epoch   90, Batch_idx  128:  Loss:   3.27509 Validation Accuracy:   0.16406\n",
      "Epoch   90, Batch_idx  256:  Loss:   3.27437 Validation Accuracy:   0.17188\n",
      "Epoch   91, Batch_idx    0:  Loss:   3.25817 Validation Accuracy:   0.15625\n",
      "Epoch   91, Batch_idx  128:  Loss:   3.19921 Validation Accuracy:   0.14844\n",
      "Epoch   91, Batch_idx  256:  Loss:   3.22132 Validation Accuracy:   0.13281\n",
      "Epoch   92, Batch_idx    0:  Loss:   3.33586 Validation Accuracy:   0.13281\n",
      "Epoch   92, Batch_idx  128:  Loss:   3.38891 Validation Accuracy:   0.11719\n",
      "Epoch   92, Batch_idx  256:  Loss:   3.41073 Validation Accuracy:   0.11719\n",
      "Epoch   93, Batch_idx    0:  Loss:   3.44106 Validation Accuracy:   0.07812\n",
      "Epoch   93, Batch_idx  128:  Loss:   3.44550 Validation Accuracy:   0.07812\n",
      "Epoch   93, Batch_idx  256:  Loss:   3.44427 Validation Accuracy:   0.07812\n",
      "Epoch   94, Batch_idx    0:  Loss:   3.38458 Validation Accuracy:   0.10156\n",
      "Epoch   94, Batch_idx  128:  Loss:   3.37535 Validation Accuracy:   0.10156\n",
      "Epoch   94, Batch_idx  256:  Loss:   3.36299 Validation Accuracy:   0.10156\n",
      "Epoch   95, Batch_idx    0:  Loss:   3.39887 Validation Accuracy:   0.10938\n",
      "Epoch   95, Batch_idx  128:  Loss:   3.38343 Validation Accuracy:   0.10938\n",
      "Epoch   95, Batch_idx  256:  Loss:   3.36803 Validation Accuracy:   0.11719\n",
      "Epoch   96, Batch_idx    0:  Loss:   3.43527 Validation Accuracy:   0.11719\n",
      "Epoch   96, Batch_idx  128:  Loss:   3.42580 Validation Accuracy:   0.11719\n",
      "Epoch   96, Batch_idx  256:  Loss:   3.41303 Validation Accuracy:   0.14062\n",
      "Epoch   97, Batch_idx    0:  Loss:   3.34678 Validation Accuracy:   0.12500\n",
      "Epoch   97, Batch_idx  128:  Loss:   3.31958 Validation Accuracy:   0.13281\n",
      "Epoch   97, Batch_idx  256:  Loss:   3.22589 Validation Accuracy:   0.14062\n",
      "Epoch   98, Batch_idx    0:  Loss:   3.32010 Validation Accuracy:   0.11719\n",
      "Epoch   98, Batch_idx  128:  Loss:   3.29626 Validation Accuracy:   0.12500\n",
      "Epoch   98, Batch_idx  256:  Loss:   3.31090 Validation Accuracy:   0.13281\n",
      "Epoch   99, Batch_idx    0:  Loss:   3.21458 Validation Accuracy:   0.14062\n",
      "Epoch   99, Batch_idx  128:  Loss:   3.19848 Validation Accuracy:   0.15625\n",
      "Epoch   99, Batch_idx  256:  Loss:   3.16299 Validation Accuracy:   0.15625\n",
      "Epoch  100, Batch_idx    0:  Loss:   3.31097 Validation Accuracy:   0.14062\n",
      "Epoch  100, Batch_idx  128:  Loss:   3.29597 Validation Accuracy:   0.12500\n",
      "Epoch  100, Batch_idx  256:  Loss:   3.28332 Validation Accuracy:   0.12500\n",
      "Epoch  101, Batch_idx    0:  Loss:   3.34322 Validation Accuracy:   0.12500\n",
      "Epoch  101, Batch_idx  128:  Loss:   3.37232 Validation Accuracy:   0.12500\n",
      "Epoch  101, Batch_idx  256:  Loss:   3.39262 Validation Accuracy:   0.11719\n",
      "Epoch  102, Batch_idx    0:  Loss:   3.32518 Validation Accuracy:   0.12500\n",
      "Epoch  102, Batch_idx  128:  Loss:   3.33818 Validation Accuracy:   0.11719\n",
      "Epoch  102, Batch_idx  256:  Loss:   3.33847 Validation Accuracy:   0.11719\n",
      "Epoch  103, Batch_idx    0:  Loss:   3.49701 Validation Accuracy:   0.07812\n",
      "Epoch  103, Batch_idx  128:  Loss:   3.48015 Validation Accuracy:   0.07812\n",
      "Epoch  103, Batch_idx  256:  Loss:   3.44978 Validation Accuracy:   0.09375\n",
      "Epoch  104, Batch_idx    0:  Loss:   3.46622 Validation Accuracy:   0.14844\n",
      "Epoch  104, Batch_idx  128:  Loss:   3.44750 Validation Accuracy:   0.14844\n",
      "Epoch  104, Batch_idx  256:  Loss:   3.43087 Validation Accuracy:   0.15625\n",
      "Epoch  105, Batch_idx    0:  Loss:   3.30999 Validation Accuracy:   0.14062\n",
      "Epoch  105, Batch_idx  128:  Loss:   3.29209 Validation Accuracy:   0.14062\n",
      "Epoch  105, Batch_idx  256:  Loss:   3.28605 Validation Accuracy:   0.14062\n",
      "Epoch  106, Batch_idx    0:  Loss:   3.26787 Validation Accuracy:   0.14062\n",
      "Epoch  106, Batch_idx  128:  Loss:   3.23830 Validation Accuracy:   0.13281\n",
      "Epoch  106, Batch_idx  256:  Loss:   3.22540 Validation Accuracy:   0.13281\n",
      "Epoch  107, Batch_idx    0:  Loss:   3.37242 Validation Accuracy:   0.15625\n",
      "Epoch  107, Batch_idx  128:  Loss:   3.38034 Validation Accuracy:   0.14062\n",
      "Epoch  107, Batch_idx  256:  Loss:   3.34119 Validation Accuracy:   0.16406\n",
      "Epoch  108, Batch_idx    0:  Loss:   3.27372 Validation Accuracy:   0.10938\n",
      "Epoch  108, Batch_idx  128:  Loss:   3.25450 Validation Accuracy:   0.10938\n",
      "Epoch  108, Batch_idx  256:  Loss:   3.23482 Validation Accuracy:   0.12500\n",
      "Epoch  109, Batch_idx    0:  Loss:   3.40874 Validation Accuracy:   0.10938\n",
      "Epoch  109, Batch_idx  128:  Loss:   3.39979 Validation Accuracy:   0.10938\n",
      "Epoch  109, Batch_idx  256:  Loss:   3.38794 Validation Accuracy:   0.10938\n",
      "Epoch  110, Batch_idx    0:  Loss:   3.32281 Validation Accuracy:   0.12500\n",
      "Epoch  110, Batch_idx  128:  Loss:   3.31267 Validation Accuracy:   0.14062\n",
      "Epoch  110, Batch_idx  256:  Loss:   3.30282 Validation Accuracy:   0.13281\n",
      "Epoch  111, Batch_idx    0:  Loss:   3.22492 Validation Accuracy:   0.15625\n",
      "Epoch  111, Batch_idx  128:  Loss:   3.21232 Validation Accuracy:   0.14844\n",
      "Epoch  111, Batch_idx  256:  Loss:   3.21705 Validation Accuracy:   0.17188\n",
      "Epoch  112, Batch_idx    0:  Loss:   3.31115 Validation Accuracy:   0.13281\n",
      "Epoch  112, Batch_idx  128:  Loss:   3.27254 Validation Accuracy:   0.13281\n",
      "Epoch  112, Batch_idx  256:  Loss:   3.26182 Validation Accuracy:   0.10938\n",
      "Epoch  113, Batch_idx    0:  Loss:   3.11747 Validation Accuracy:   0.23438\n",
      "Epoch  113, Batch_idx  128:  Loss:   3.09587 Validation Accuracy:   0.28125\n",
      "Epoch  113, Batch_idx  256:  Loss:   3.08928 Validation Accuracy:   0.25000\n",
      "Epoch  114, Batch_idx    0:  Loss:   3.13505 Validation Accuracy:   0.19531\n",
      "Epoch  114, Batch_idx  128:  Loss:   3.12428 Validation Accuracy:   0.18750\n",
      "Epoch  114, Batch_idx  256:  Loss:   3.10070 Validation Accuracy:   0.18750\n",
      "Epoch  115, Batch_idx    0:  Loss:   3.18826 Validation Accuracy:   0.14062\n",
      "Epoch  115, Batch_idx  128:  Loss:   3.17128 Validation Accuracy:   0.17188\n",
      "Epoch  115, Batch_idx  256:  Loss:   3.14551 Validation Accuracy:   0.17969\n",
      "Epoch  116, Batch_idx    0:  Loss:   3.26539 Validation Accuracy:   0.12500\n",
      "Epoch  116, Batch_idx  128:  Loss:   3.24142 Validation Accuracy:   0.12500\n",
      "Epoch  116, Batch_idx  256:  Loss:   3.22137 Validation Accuracy:   0.12500\n",
      "Epoch  117, Batch_idx    0:  Loss:   3.23183 Validation Accuracy:   0.10156\n",
      "Epoch  117, Batch_idx  128:  Loss:   3.22811 Validation Accuracy:   0.10156\n",
      "Epoch  117, Batch_idx  256:  Loss:   3.22112 Validation Accuracy:   0.10156\n",
      "Epoch  118, Batch_idx    0:  Loss:   3.43315 Validation Accuracy:   0.08594\n",
      "Epoch  118, Batch_idx  128:  Loss:   3.42427 Validation Accuracy:   0.08594\n",
      "Epoch  118, Batch_idx  256:  Loss:   3.41268 Validation Accuracy:   0.09375\n",
      "Epoch  119, Batch_idx    0:  Loss:   3.35639 Validation Accuracy:   0.14062\n",
      "Epoch  119, Batch_idx  128:  Loss:   3.33617 Validation Accuracy:   0.14062\n",
      "Epoch  119, Batch_idx  256:  Loss:   3.31400 Validation Accuracy:   0.13281\n",
      "Epoch  120, Batch_idx    0:  Loss:   3.28557 Validation Accuracy:   0.12500\n",
      "Epoch  120, Batch_idx  128:  Loss:   3.23420 Validation Accuracy:   0.14844\n",
      "Epoch  120, Batch_idx  256:  Loss:   3.18099 Validation Accuracy:   0.17188\n",
      "Epoch  121, Batch_idx    0:  Loss:   3.32221 Validation Accuracy:   0.10938\n",
      "Epoch  121, Batch_idx  128:  Loss:   3.33150 Validation Accuracy:   0.12500\n",
      "Epoch  121, Batch_idx  256:  Loss:   3.30268 Validation Accuracy:   0.12500\n",
      "Epoch  122, Batch_idx    0:  Loss:   3.36867 Validation Accuracy:   0.14062\n",
      "Epoch  122, Batch_idx  128:  Loss:   3.39672 Validation Accuracy:   0.14844\n",
      "Epoch  122, Batch_idx  256:  Loss:   3.36300 Validation Accuracy:   0.14844\n",
      "Epoch  123, Batch_idx    0:  Loss:   3.29653 Validation Accuracy:   0.12500\n",
      "Epoch  123, Batch_idx  128:  Loss:   3.28159 Validation Accuracy:   0.14062\n",
      "Epoch  123, Batch_idx  256:  Loss:   3.26082 Validation Accuracy:   0.10156\n",
      "Epoch  124, Batch_idx    0:  Loss:   3.20199 Validation Accuracy:   0.11719\n",
      "Epoch  124, Batch_idx  128:  Loss:   3.19578 Validation Accuracy:   0.12500\n",
      "Epoch  124, Batch_idx  256:  Loss:   3.19929 Validation Accuracy:   0.13281\n",
      "Epoch  125, Batch_idx    0:  Loss:   3.24365 Validation Accuracy:   0.13281\n",
      "Epoch  125, Batch_idx  128:  Loss:   3.24325 Validation Accuracy:   0.13281\n",
      "Epoch  125, Batch_idx  256:  Loss:   3.23709 Validation Accuracy:   0.12500\n",
      "Epoch  126, Batch_idx    0:  Loss:   3.25637 Validation Accuracy:   0.14062\n",
      "Epoch  126, Batch_idx  128:  Loss:   3.21842 Validation Accuracy:   0.13281\n",
      "Epoch  126, Batch_idx  256:  Loss:   3.17814 Validation Accuracy:   0.15625\n",
      "Epoch  127, Batch_idx    0:  Loss:   3.22970 Validation Accuracy:   0.12500\n",
      "Epoch  127, Batch_idx  128:  Loss:   3.17350 Validation Accuracy:   0.14844\n",
      "Epoch  127, Batch_idx  256:  Loss:   3.15471 Validation Accuracy:   0.17969\n",
      "Epoch  128, Batch_idx    0:  Loss:   3.22434 Validation Accuracy:   0.07812\n",
      "Epoch  128, Batch_idx  128:  Loss:   3.20516 Validation Accuracy:   0.07812\n",
      "Epoch  128, Batch_idx  256:  Loss:   3.20371 Validation Accuracy:   0.10156\n",
      "Epoch  129, Batch_idx    0:  Loss:   3.01661 Validation Accuracy:   0.20312\n",
      "Epoch  129, Batch_idx  128:  Loss:   3.02270 Validation Accuracy:   0.18750\n",
      "Epoch  129, Batch_idx  256:  Loss:   3.01935 Validation Accuracy:   0.17188\n",
      "Epoch  130, Batch_idx    0:  Loss:   3.10819 Validation Accuracy:   0.13281\n",
      "Epoch  130, Batch_idx  128:  Loss:   3.09198 Validation Accuracy:   0.12500\n",
      "Epoch  130, Batch_idx  256:  Loss:   3.09175 Validation Accuracy:   0.12500\n",
      "Epoch  131, Batch_idx    0:  Loss:   3.16077 Validation Accuracy:   0.16406\n",
      "Epoch  131, Batch_idx  128:  Loss:   3.18993 Validation Accuracy:   0.16406\n",
      "Epoch  131, Batch_idx  256:  Loss:   3.17913 Validation Accuracy:   0.16406\n",
      "Epoch  132, Batch_idx    0:  Loss:   3.06229 Validation Accuracy:   0.20312\n",
      "Epoch  132, Batch_idx  128:  Loss:   3.03152 Validation Accuracy:   0.22656\n",
      "Epoch  132, Batch_idx  256:  Loss:   3.02762 Validation Accuracy:   0.21094\n",
      "Epoch  133, Batch_idx    0:  Loss:   3.03492 Validation Accuracy:   0.17188\n",
      "Epoch  133, Batch_idx  128:  Loss:   2.99272 Validation Accuracy:   0.17188\n",
      "Epoch  133, Batch_idx  256:  Loss:   2.97353 Validation Accuracy:   0.17969\n",
      "Epoch  134, Batch_idx    0:  Loss:   3.27476 Validation Accuracy:   0.14844\n",
      "Epoch  134, Batch_idx  128:  Loss:   3.30689 Validation Accuracy:   0.13281\n",
      "Epoch  134, Batch_idx  256:  Loss:   3.31311 Validation Accuracy:   0.13281\n",
      "Epoch  135, Batch_idx    0:  Loss:   3.36800 Validation Accuracy:   0.09375\n",
      "Epoch  135, Batch_idx  128:  Loss:   3.36031 Validation Accuracy:   0.09375\n",
      "Epoch  135, Batch_idx  256:  Loss:   3.33099 Validation Accuracy:   0.10156\n",
      "Epoch  136, Batch_idx    0:  Loss:   3.12771 Validation Accuracy:   0.14844\n",
      "Epoch  136, Batch_idx  128:  Loss:   3.14619 Validation Accuracy:   0.13281\n",
      "Epoch  136, Batch_idx  256:  Loss:   3.08395 Validation Accuracy:   0.17969\n",
      "Epoch  137, Batch_idx    0:  Loss:   3.08233 Validation Accuracy:   0.20312\n",
      "Epoch  137, Batch_idx  128:  Loss:   3.05059 Validation Accuracy:   0.21875\n",
      "Epoch  137, Batch_idx  256:  Loss:   2.97204 Validation Accuracy:   0.24219\n",
      "Epoch  138, Batch_idx    0:  Loss:   3.20951 Validation Accuracy:   0.16406\n",
      "Epoch  138, Batch_idx  128:  Loss:   3.22310 Validation Accuracy:   0.17969\n",
      "Epoch  138, Batch_idx  256:  Loss:   3.22322 Validation Accuracy:   0.17969\n",
      "Epoch  139, Batch_idx    0:  Loss:   3.20020 Validation Accuracy:   0.14844\n",
      "Epoch  139, Batch_idx  128:  Loss:   3.17437 Validation Accuracy:   0.17188\n",
      "Epoch  139, Batch_idx  256:  Loss:   3.07921 Validation Accuracy:   0.18750\n",
      "Epoch  140, Batch_idx    0:  Loss:   3.12435 Validation Accuracy:   0.17969\n",
      "Epoch  140, Batch_idx  128:  Loss:   3.15840 Validation Accuracy:   0.17969\n",
      "Epoch  140, Batch_idx  256:  Loss:   3.05932 Validation Accuracy:   0.17969\n",
      "Epoch  141, Batch_idx    0:  Loss:   3.18458 Validation Accuracy:   0.14062\n",
      "Epoch  141, Batch_idx  128:  Loss:   3.21098 Validation Accuracy:   0.14844\n",
      "Epoch  141, Batch_idx  256:  Loss:   3.21015 Validation Accuracy:   0.14844\n",
      "Epoch  142, Batch_idx    0:  Loss:   3.42423 Validation Accuracy:   0.13281\n",
      "Epoch  142, Batch_idx  128:  Loss:   3.39299 Validation Accuracy:   0.14062\n",
      "Epoch  142, Batch_idx  256:  Loss:   3.35733 Validation Accuracy:   0.13281\n",
      "Epoch  143, Batch_idx    0:  Loss:   3.43376 Validation Accuracy:   0.08594\n",
      "Epoch  143, Batch_idx  128:  Loss:   3.40206 Validation Accuracy:   0.09375\n",
      "Epoch  143, Batch_idx  256:  Loss:   3.35021 Validation Accuracy:   0.10156\n",
      "Epoch  144, Batch_idx    0:  Loss:   3.24709 Validation Accuracy:   0.17188\n",
      "Epoch  144, Batch_idx  128:  Loss:   3.21629 Validation Accuracy:   0.19531\n",
      "Epoch  144, Batch_idx  256:  Loss:   3.19125 Validation Accuracy:   0.22656\n",
      "Epoch  145, Batch_idx    0:  Loss:   3.21789 Validation Accuracy:   0.12500\n",
      "Epoch  145, Batch_idx  128:  Loss:   3.17374 Validation Accuracy:   0.13281\n",
      "Epoch  145, Batch_idx  256:  Loss:   3.14095 Validation Accuracy:   0.17969\n",
      "Epoch  146, Batch_idx    0:  Loss:   3.19502 Validation Accuracy:   0.14062\n",
      "Epoch  146, Batch_idx  128:  Loss:   3.20252 Validation Accuracy:   0.14062\n",
      "Epoch  146, Batch_idx  256:  Loss:   3.21593 Validation Accuracy:   0.15625\n",
      "Epoch  147, Batch_idx    0:  Loss:   3.10604 Validation Accuracy:   0.18750\n",
      "Epoch  147, Batch_idx  128:  Loss:   3.07681 Validation Accuracy:   0.20312\n",
      "Epoch  147, Batch_idx  256:  Loss:   3.01737 Validation Accuracy:   0.22656\n",
      "Epoch  148, Batch_idx    0:  Loss:   2.98883 Validation Accuracy:   0.17969\n",
      "Epoch  148, Batch_idx  128:  Loss:   2.96705 Validation Accuracy:   0.17969\n",
      "Epoch  148, Batch_idx  256:  Loss:   2.97702 Validation Accuracy:   0.18750\n",
      "Epoch  149, Batch_idx    0:  Loss:   3.05068 Validation Accuracy:   0.18750\n",
      "Epoch  149, Batch_idx  128:  Loss:   3.07861 Validation Accuracy:   0.16406\n",
      "Epoch  149, Batch_idx  256:  Loss:   3.09160 Validation Accuracy:   0.15625\n",
      "Epoch  150, Batch_idx    0:  Loss:   2.98632 Validation Accuracy:   0.19531\n",
      "Epoch  150, Batch_idx  128:  Loss:   2.94540 Validation Accuracy:   0.22656\n",
      "Epoch  150, Batch_idx  256:  Loss:   2.88958 Validation Accuracy:   0.24219\n",
      "Epoch  151, Batch_idx    0:  Loss:   3.01209 Validation Accuracy:   0.19531\n",
      "Epoch  151, Batch_idx  128:  Loss:   2.98497 Validation Accuracy:   0.21094\n",
      "Epoch  151, Batch_idx  256:  Loss:   3.00959 Validation Accuracy:   0.19531\n",
      "Epoch  152, Batch_idx    0:  Loss:   3.32692 Validation Accuracy:   0.16406\n",
      "Epoch  152, Batch_idx  128:  Loss:   3.32452 Validation Accuracy:   0.15625\n",
      "Epoch  152, Batch_idx  256:  Loss:   3.27414 Validation Accuracy:   0.15625\n",
      "Epoch  153, Batch_idx    0:  Loss:   3.06025 Validation Accuracy:   0.20312\n",
      "Epoch  153, Batch_idx  128:  Loss:   3.04905 Validation Accuracy:   0.18750\n",
      "Epoch  153, Batch_idx  256:  Loss:   3.04849 Validation Accuracy:   0.17969\n",
      "Epoch  154, Batch_idx    0:  Loss:   2.87170 Validation Accuracy:   0.19531\n",
      "Epoch  154, Batch_idx  128:  Loss:   2.88744 Validation Accuracy:   0.19531\n",
      "Epoch  154, Batch_idx  256:  Loss:   2.89085 Validation Accuracy:   0.21875\n",
      "Epoch  155, Batch_idx    0:  Loss:   3.11281 Validation Accuracy:   0.19531\n",
      "Epoch  155, Batch_idx  128:  Loss:   3.03617 Validation Accuracy:   0.17188\n",
      "Epoch  155, Batch_idx  256:  Loss:   3.07173 Validation Accuracy:   0.14844\n",
      "Epoch  156, Batch_idx    0:  Loss:   3.20165 Validation Accuracy:   0.10938\n",
      "Epoch  156, Batch_idx  128:  Loss:   3.19562 Validation Accuracy:   0.10938\n",
      "Epoch  156, Batch_idx  256:  Loss:   3.20068 Validation Accuracy:   0.12500\n",
      "Epoch  157, Batch_idx    0:  Loss:   3.12901 Validation Accuracy:   0.13281\n",
      "Epoch  157, Batch_idx  128:  Loss:   3.05565 Validation Accuracy:   0.21875\n",
      "Epoch  157, Batch_idx  256:  Loss:   3.01795 Validation Accuracy:   0.21094\n",
      "Epoch  158, Batch_idx    0:  Loss:   3.10732 Validation Accuracy:   0.17969\n",
      "Epoch  158, Batch_idx  128:  Loss:   3.10618 Validation Accuracy:   0.18750\n",
      "Epoch  158, Batch_idx  256:  Loss:   3.07900 Validation Accuracy:   0.21094\n",
      "Epoch  159, Batch_idx    0:  Loss:   3.09009 Validation Accuracy:   0.12500\n",
      "Epoch  159, Batch_idx  128:  Loss:   3.08893 Validation Accuracy:   0.12500\n",
      "Epoch  159, Batch_idx  256:  Loss:   3.09157 Validation Accuracy:   0.14062\n",
      "Epoch  160, Batch_idx    0:  Loss:   3.13594 Validation Accuracy:   0.12500\n",
      "Epoch  160, Batch_idx  128:  Loss:   3.10902 Validation Accuracy:   0.12500\n",
      "Epoch  160, Batch_idx  256:  Loss:   3.08718 Validation Accuracy:   0.12500\n",
      "Epoch  161, Batch_idx    0:  Loss:   3.11850 Validation Accuracy:   0.13281\n",
      "Epoch  161, Batch_idx  128:  Loss:   3.07288 Validation Accuracy:   0.14844\n",
      "Epoch  161, Batch_idx  256:  Loss:   3.04969 Validation Accuracy:   0.14844\n",
      "Epoch  162, Batch_idx    0:  Loss:   3.02925 Validation Accuracy:   0.18750\n",
      "Epoch  162, Batch_idx  128:  Loss:   3.06742 Validation Accuracy:   0.20312\n",
      "Epoch  162, Batch_idx  256:  Loss:   2.99180 Validation Accuracy:   0.22656\n",
      "Epoch  163, Batch_idx    0:  Loss:   2.99882 Validation Accuracy:   0.17969\n",
      "Epoch  163, Batch_idx  128:  Loss:   3.02132 Validation Accuracy:   0.15625\n",
      "Epoch  163, Batch_idx  256:  Loss:   2.95840 Validation Accuracy:   0.16406\n",
      "Epoch  164, Batch_idx    0:  Loss:   3.12397 Validation Accuracy:   0.18750\n",
      "Epoch  164, Batch_idx  128:  Loss:   3.13146 Validation Accuracy:   0.18750\n",
      "Epoch  164, Batch_idx  256:  Loss:   3.12603 Validation Accuracy:   0.18750\n",
      "Epoch  165, Batch_idx    0:  Loss:   2.86738 Validation Accuracy:   0.23438\n",
      "Epoch  165, Batch_idx  128:  Loss:   2.84087 Validation Accuracy:   0.23438\n",
      "Epoch  165, Batch_idx  256:  Loss:   2.81519 Validation Accuracy:   0.23438\n",
      "Epoch  166, Batch_idx    0:  Loss:   2.96239 Validation Accuracy:   0.17188\n",
      "Epoch  166, Batch_idx  128:  Loss:   2.95050 Validation Accuracy:   0.17188\n",
      "Epoch  166, Batch_idx  256:  Loss:   2.92177 Validation Accuracy:   0.17969\n",
      "Epoch  167, Batch_idx    0:  Loss:   2.98733 Validation Accuracy:   0.16406\n",
      "Epoch  167, Batch_idx  128:  Loss:   3.06999 Validation Accuracy:   0.15625\n",
      "Epoch  167, Batch_idx  256:  Loss:   3.09685 Validation Accuracy:   0.17188\n",
      "Epoch  168, Batch_idx    0:  Loss:   3.08752 Validation Accuracy:   0.17969\n",
      "Epoch  168, Batch_idx  128:  Loss:   2.97654 Validation Accuracy:   0.19531\n",
      "Epoch  168, Batch_idx  256:  Loss:   2.94719 Validation Accuracy:   0.18750\n",
      "Epoch  169, Batch_idx    0:  Loss:   3.02258 Validation Accuracy:   0.15625\n",
      "Epoch  169, Batch_idx  128:  Loss:   2.97445 Validation Accuracy:   0.15625\n",
      "Epoch  169, Batch_idx  256:  Loss:   2.96692 Validation Accuracy:   0.17188\n",
      "Epoch  170, Batch_idx    0:  Loss:   3.00754 Validation Accuracy:   0.17969\n",
      "Epoch  170, Batch_idx  128:  Loss:   3.07887 Validation Accuracy:   0.16406\n",
      "Epoch  170, Batch_idx  256:  Loss:   3.01531 Validation Accuracy:   0.20312\n",
      "Epoch  171, Batch_idx    0:  Loss:   3.11945 Validation Accuracy:   0.21875\n",
      "Epoch  171, Batch_idx  128:  Loss:   3.10783 Validation Accuracy:   0.17188\n",
      "Epoch  171, Batch_idx  256:  Loss:   3.11963 Validation Accuracy:   0.15625\n",
      "Epoch  172, Batch_idx    0:  Loss:   3.14510 Validation Accuracy:   0.12500\n",
      "Epoch  172, Batch_idx  128:  Loss:   3.14935 Validation Accuracy:   0.11719\n",
      "Epoch  172, Batch_idx  256:  Loss:   3.13768 Validation Accuracy:   0.13281\n",
      "Epoch  173, Batch_idx    0:  Loss:   2.94144 Validation Accuracy:   0.14844\n",
      "Epoch  173, Batch_idx  128:  Loss:   2.91663 Validation Accuracy:   0.17188\n",
      "Epoch  173, Batch_idx  256:  Loss:   2.88641 Validation Accuracy:   0.17188\n",
      "Epoch  174, Batch_idx    0:  Loss:   2.87323 Validation Accuracy:   0.21094\n",
      "Epoch  174, Batch_idx  128:  Loss:   2.84997 Validation Accuracy:   0.21094\n",
      "Epoch  174, Batch_idx  256:  Loss:   2.82525 Validation Accuracy:   0.21094\n",
      "Epoch  175, Batch_idx    0:  Loss:   2.86001 Validation Accuracy:   0.23438\n",
      "Epoch  175, Batch_idx  128:  Loss:   2.86862 Validation Accuracy:   0.24219\n",
      "Epoch  175, Batch_idx  256:  Loss:   2.84277 Validation Accuracy:   0.25000\n",
      "Epoch  176, Batch_idx    0:  Loss:   2.94390 Validation Accuracy:   0.24219\n",
      "Epoch  176, Batch_idx  128:  Loss:   2.88707 Validation Accuracy:   0.25781\n",
      "Epoch  176, Batch_idx  256:  Loss:   2.90990 Validation Accuracy:   0.24219\n",
      "Epoch  177, Batch_idx    0:  Loss:   2.97950 Validation Accuracy:   0.22656\n",
      "Epoch  177, Batch_idx  128:  Loss:   2.89611 Validation Accuracy:   0.22656\n",
      "Epoch  177, Batch_idx  256:  Loss:   2.90390 Validation Accuracy:   0.22656\n",
      "Epoch  178, Batch_idx    0:  Loss:   3.06517 Validation Accuracy:   0.19531\n",
      "Epoch  178, Batch_idx  128:  Loss:   3.06560 Validation Accuracy:   0.17969\n",
      "Epoch  178, Batch_idx  256:  Loss:   3.07802 Validation Accuracy:   0.19531\n",
      "Epoch  179, Batch_idx    0:  Loss:   3.01606 Validation Accuracy:   0.15625\n",
      "Epoch  179, Batch_idx  128:  Loss:   2.98379 Validation Accuracy:   0.16406\n",
      "Epoch  179, Batch_idx  256:  Loss:   2.96091 Validation Accuracy:   0.17188\n",
      "Epoch  180, Batch_idx    0:  Loss:   3.19264 Validation Accuracy:   0.15625\n",
      "Epoch  180, Batch_idx  128:  Loss:   3.18024 Validation Accuracy:   0.16406\n",
      "Epoch  180, Batch_idx  256:  Loss:   3.15706 Validation Accuracy:   0.15625\n",
      "Epoch  181, Batch_idx    0:  Loss:   2.90251 Validation Accuracy:   0.19531\n",
      "Epoch  181, Batch_idx  128:  Loss:   2.85165 Validation Accuracy:   0.21094\n",
      "Epoch  181, Batch_idx  256:  Loss:   2.80979 Validation Accuracy:   0.21875\n",
      "Epoch  182, Batch_idx    0:  Loss:   2.84621 Validation Accuracy:   0.23438\n",
      "Epoch  182, Batch_idx  128:  Loss:   2.81865 Validation Accuracy:   0.25781\n",
      "Epoch  182, Batch_idx  256:  Loss:   2.80255 Validation Accuracy:   0.25781\n",
      "Epoch  183, Batch_idx    0:  Loss:   3.07941 Validation Accuracy:   0.16406\n",
      "Epoch  183, Batch_idx  128:  Loss:   3.04815 Validation Accuracy:   0.16406\n",
      "Epoch  183, Batch_idx  256:  Loss:   3.02010 Validation Accuracy:   0.17188\n",
      "Epoch  184, Batch_idx    0:  Loss:   2.80375 Validation Accuracy:   0.20312\n",
      "Epoch  184, Batch_idx  128:  Loss:   2.79034 Validation Accuracy:   0.19531\n",
      "Epoch  184, Batch_idx  256:  Loss:   2.77520 Validation Accuracy:   0.20312\n",
      "Epoch  185, Batch_idx    0:  Loss:   2.86187 Validation Accuracy:   0.21094\n",
      "Epoch  185, Batch_idx  128:  Loss:   2.80861 Validation Accuracy:   0.22656\n",
      "Epoch  185, Batch_idx  256:  Loss:   2.76344 Validation Accuracy:   0.22656\n",
      "Epoch  186, Batch_idx    0:  Loss:   2.92676 Validation Accuracy:   0.20312\n",
      "Epoch  186, Batch_idx  128:  Loss:   2.90568 Validation Accuracy:   0.20312\n",
      "Epoch  186, Batch_idx  256:  Loss:   2.83510 Validation Accuracy:   0.21094\n",
      "Epoch  187, Batch_idx    0:  Loss:   2.72485 Validation Accuracy:   0.21875\n",
      "Epoch  187, Batch_idx  128:  Loss:   2.70626 Validation Accuracy:   0.22656\n",
      "Epoch  187, Batch_idx  256:  Loss:   2.68995 Validation Accuracy:   0.23438\n",
      "Epoch  188, Batch_idx    0:  Loss:   2.82972 Validation Accuracy:   0.19531\n",
      "Epoch  188, Batch_idx  128:  Loss:   2.88631 Validation Accuracy:   0.19531\n",
      "Epoch  188, Batch_idx  256:  Loss:   2.81712 Validation Accuracy:   0.25000\n",
      "Epoch  189, Batch_idx    0:  Loss:   2.96440 Validation Accuracy:   0.18750\n",
      "Epoch  189, Batch_idx  128:  Loss:   2.95859 Validation Accuracy:   0.20312\n",
      "Epoch  189, Batch_idx  256:  Loss:   2.96800 Validation Accuracy:   0.18750\n",
      "Epoch  190, Batch_idx    0:  Loss:   2.92034 Validation Accuracy:   0.20312\n",
      "Epoch  190, Batch_idx  128:  Loss:   2.90618 Validation Accuracy:   0.21094\n",
      "Epoch  190, Batch_idx  256:  Loss:   2.88660 Validation Accuracy:   0.22656\n",
      "Epoch  191, Batch_idx    0:  Loss:   3.04089 Validation Accuracy:   0.12500\n",
      "Epoch  191, Batch_idx  128:  Loss:   3.02445 Validation Accuracy:   0.13281\n",
      "Epoch  191, Batch_idx  256:  Loss:   2.99580 Validation Accuracy:   0.13281\n",
      "Epoch  192, Batch_idx    0:  Loss:   3.14418 Validation Accuracy:   0.13281\n",
      "Epoch  192, Batch_idx  128:  Loss:   3.13356 Validation Accuracy:   0.13281\n",
      "Epoch  192, Batch_idx  256:  Loss:   3.12225 Validation Accuracy:   0.13281\n",
      "Epoch  193, Batch_idx    0:  Loss:   2.92396 Validation Accuracy:   0.17188\n",
      "Epoch  193, Batch_idx  128:  Loss:   2.89201 Validation Accuracy:   0.16406\n",
      "Epoch  193, Batch_idx  256:  Loss:   2.86904 Validation Accuracy:   0.16406\n",
      "Epoch  194, Batch_idx    0:  Loss:   2.84419 Validation Accuracy:   0.23438\n",
      "Epoch  194, Batch_idx  128:  Loss:   2.82024 Validation Accuracy:   0.23438\n",
      "Epoch  194, Batch_idx  256:  Loss:   2.81171 Validation Accuracy:   0.23438\n",
      "Epoch  195, Batch_idx    0:  Loss:   3.01606 Validation Accuracy:   0.16406\n",
      "Epoch  195, Batch_idx  128:  Loss:   3.03849 Validation Accuracy:   0.17188\n",
      "Epoch  195, Batch_idx  256:  Loss:   3.00099 Validation Accuracy:   0.17188\n",
      "Epoch  196, Batch_idx    0:  Loss:   2.97207 Validation Accuracy:   0.16406\n",
      "Epoch  196, Batch_idx  128:  Loss:   3.02129 Validation Accuracy:   0.16406\n",
      "Epoch  196, Batch_idx  256:  Loss:   2.96285 Validation Accuracy:   0.17969\n",
      "Epoch  197, Batch_idx    0:  Loss:   2.84664 Validation Accuracy:   0.18750\n",
      "Epoch  197, Batch_idx  128:  Loss:   2.83533 Validation Accuracy:   0.19531\n",
      "Epoch  197, Batch_idx  256:  Loss:   2.81753 Validation Accuracy:   0.21094\n",
      "Epoch  198, Batch_idx    0:  Loss:   3.21231 Validation Accuracy:   0.14062\n",
      "Epoch  198, Batch_idx  128:  Loss:   3.19132 Validation Accuracy:   0.14062\n",
      "Epoch  198, Batch_idx  256:  Loss:   3.16872 Validation Accuracy:   0.15625\n",
      "Epoch  199, Batch_idx    0:  Loss:   2.91001 Validation Accuracy:   0.21875\n",
      "Epoch  199, Batch_idx  128:  Loss:   2.88065 Validation Accuracy:   0.21875\n",
      "Epoch  199, Batch_idx  256:  Loss:   2.84782 Validation Accuracy:   0.22656\n",
      "Epoch  200, Batch_idx    0:  Loss:   2.76810 Validation Accuracy:   0.20312\n",
      "Epoch  200, Batch_idx  128:  Loss:   2.72670 Validation Accuracy:   0.21094\n",
      "Epoch  200, Batch_idx  256:  Loss:   2.71451 Validation Accuracy:   0.21875\n",
      "Epoch  201, Batch_idx    0:  Loss:   3.08870 Validation Accuracy:   0.15625\n",
      "Epoch  201, Batch_idx  128:  Loss:   3.09129 Validation Accuracy:   0.16406\n",
      "Epoch  201, Batch_idx  256:  Loss:   3.03381 Validation Accuracy:   0.17188\n",
      "Epoch  202, Batch_idx    0:  Loss:   2.79207 Validation Accuracy:   0.25000\n",
      "Epoch  202, Batch_idx  128:  Loss:   2.79073 Validation Accuracy:   0.25781\n",
      "Epoch  202, Batch_idx  256:  Loss:   2.76513 Validation Accuracy:   0.26562\n",
      "Epoch  203, Batch_idx    0:  Loss:   2.96185 Validation Accuracy:   0.21875\n",
      "Epoch  203, Batch_idx  128:  Loss:   2.96130 Validation Accuracy:   0.21875\n",
      "Epoch  203, Batch_idx  256:  Loss:   2.91932 Validation Accuracy:   0.22656\n",
      "Epoch  204, Batch_idx    0:  Loss:   2.92925 Validation Accuracy:   0.17969\n",
      "Epoch  204, Batch_idx  128:  Loss:   2.92483 Validation Accuracy:   0.20312\n",
      "Epoch  204, Batch_idx  256:  Loss:   2.89215 Validation Accuracy:   0.21094\n",
      "Epoch  205, Batch_idx    0:  Loss:   2.95666 Validation Accuracy:   0.14844\n",
      "Epoch  205, Batch_idx  128:  Loss:   2.95135 Validation Accuracy:   0.14844\n",
      "Epoch  205, Batch_idx  256:  Loss:   2.89515 Validation Accuracy:   0.17188\n",
      "Epoch  206, Batch_idx    0:  Loss:   2.61957 Validation Accuracy:   0.24219\n",
      "Epoch  206, Batch_idx  128:  Loss:   2.71177 Validation Accuracy:   0.21094\n",
      "Epoch  206, Batch_idx  256:  Loss:   2.55920 Validation Accuracy:   0.23438\n",
      "Epoch  207, Batch_idx    0:  Loss:   2.80645 Validation Accuracy:   0.20312\n",
      "Epoch  207, Batch_idx  128:  Loss:   2.83750 Validation Accuracy:   0.16406\n",
      "Epoch  207, Batch_idx  256:  Loss:   2.79179 Validation Accuracy:   0.20312\n",
      "Epoch  208, Batch_idx    0:  Loss:   2.88562 Validation Accuracy:   0.20312\n",
      "Epoch  208, Batch_idx  128:  Loss:   2.88971 Validation Accuracy:   0.20312\n",
      "Epoch  208, Batch_idx  256:  Loss:   2.88437 Validation Accuracy:   0.21094\n",
      "Epoch  209, Batch_idx    0:  Loss:   2.85823 Validation Accuracy:   0.19531\n",
      "Epoch  209, Batch_idx  128:  Loss:   2.84759 Validation Accuracy:   0.18750\n",
      "Epoch  209, Batch_idx  256:  Loss:   2.81676 Validation Accuracy:   0.20312\n",
      "Epoch  210, Batch_idx    0:  Loss:   2.82305 Validation Accuracy:   0.19531\n",
      "Epoch  210, Batch_idx  128:  Loss:   2.78926 Validation Accuracy:   0.21875\n",
      "Epoch  210, Batch_idx  256:  Loss:   2.77277 Validation Accuracy:   0.21875\n",
      "Epoch  211, Batch_idx    0:  Loss:   2.99956 Validation Accuracy:   0.16406\n",
      "Epoch  211, Batch_idx  128:  Loss:   2.99323 Validation Accuracy:   0.14062\n",
      "Epoch  211, Batch_idx  256:  Loss:   2.97297 Validation Accuracy:   0.14062\n",
      "Epoch  212, Batch_idx    0:  Loss:   2.88265 Validation Accuracy:   0.14844\n",
      "Epoch  212, Batch_idx  128:  Loss:   2.85571 Validation Accuracy:   0.18750\n",
      "Epoch  212, Batch_idx  256:  Loss:   2.82123 Validation Accuracy:   0.17969\n",
      "Epoch  213, Batch_idx    0:  Loss:   2.91989 Validation Accuracy:   0.13281\n",
      "Epoch  213, Batch_idx  128:  Loss:   2.91602 Validation Accuracy:   0.13281\n",
      "Epoch  213, Batch_idx  256:  Loss:   2.89578 Validation Accuracy:   0.13281\n",
      "Epoch  214, Batch_idx    0:  Loss:   2.90175 Validation Accuracy:   0.21875\n",
      "Epoch  214, Batch_idx  128:  Loss:   2.88573 Validation Accuracy:   0.21094\n",
      "Epoch  214, Batch_idx  256:  Loss:   2.87578 Validation Accuracy:   0.21094\n",
      "Epoch  215, Batch_idx    0:  Loss:   2.80854 Validation Accuracy:   0.17188\n",
      "Epoch  215, Batch_idx  128:  Loss:   2.79215 Validation Accuracy:   0.17188\n",
      "Epoch  215, Batch_idx  256:  Loss:   2.77433 Validation Accuracy:   0.24219\n",
      "Epoch  216, Batch_idx    0:  Loss:   2.77847 Validation Accuracy:   0.13281\n",
      "Epoch  216, Batch_idx  128:  Loss:   2.74670 Validation Accuracy:   0.14062\n",
      "Epoch  216, Batch_idx  256:  Loss:   2.74361 Validation Accuracy:   0.15625\n",
      "Epoch  217, Batch_idx    0:  Loss:   2.55864 Validation Accuracy:   0.25781\n",
      "Epoch  217, Batch_idx  128:  Loss:   2.52916 Validation Accuracy:   0.29688\n",
      "Epoch  217, Batch_idx  256:  Loss:   2.51297 Validation Accuracy:   0.32031\n",
      "Epoch  218, Batch_idx    0:  Loss:   2.78985 Validation Accuracy:   0.20312\n",
      "Epoch  218, Batch_idx  128:  Loss:   2.77255 Validation Accuracy:   0.21094\n",
      "Epoch  218, Batch_idx  256:  Loss:   2.75116 Validation Accuracy:   0.21875\n",
      "Epoch  219, Batch_idx    0:  Loss:   2.92171 Validation Accuracy:   0.17969\n",
      "Epoch  219, Batch_idx  128:  Loss:   2.88818 Validation Accuracy:   0.17969\n",
      "Epoch  219, Batch_idx  256:  Loss:   2.85041 Validation Accuracy:   0.18750\n",
      "Epoch  220, Batch_idx    0:  Loss:   2.93916 Validation Accuracy:   0.22656\n",
      "Epoch  220, Batch_idx  128:  Loss:   2.91306 Validation Accuracy:   0.22656\n",
      "Epoch  220, Batch_idx  256:  Loss:   2.86717 Validation Accuracy:   0.22656\n",
      "Epoch  221, Batch_idx    0:  Loss:   2.76378 Validation Accuracy:   0.18750\n",
      "Epoch  221, Batch_idx  128:  Loss:   2.74852 Validation Accuracy:   0.21094\n",
      "Epoch  221, Batch_idx  256:  Loss:   2.73824 Validation Accuracy:   0.22656\n",
      "Epoch  222, Batch_idx    0:  Loss:   2.92034 Validation Accuracy:   0.14844\n",
      "Epoch  222, Batch_idx  128:  Loss:   2.90477 Validation Accuracy:   0.15625\n",
      "Epoch  222, Batch_idx  256:  Loss:   2.87202 Validation Accuracy:   0.15625\n",
      "Epoch  223, Batch_idx    0:  Loss:   2.91750 Validation Accuracy:   0.17969\n",
      "Epoch  223, Batch_idx  128:  Loss:   2.93705 Validation Accuracy:   0.17969\n",
      "Epoch  223, Batch_idx  256:  Loss:   2.91049 Validation Accuracy:   0.17188\n",
      "Epoch  224, Batch_idx    0:  Loss:   3.01873 Validation Accuracy:   0.13281\n",
      "Epoch  224, Batch_idx  128:  Loss:   3.04621 Validation Accuracy:   0.13281\n",
      "Epoch  224, Batch_idx  256:  Loss:   3.01079 Validation Accuracy:   0.14844\n",
      "Epoch  225, Batch_idx    0:  Loss:   2.88550 Validation Accuracy:   0.16406\n",
      "Epoch  225, Batch_idx  128:  Loss:   2.87586 Validation Accuracy:   0.15625\n",
      "Epoch  225, Batch_idx  256:  Loss:   2.86572 Validation Accuracy:   0.14062\n",
      "Epoch  226, Batch_idx    0:  Loss:   2.87242 Validation Accuracy:   0.24219\n",
      "Epoch  226, Batch_idx  128:  Loss:   2.97678 Validation Accuracy:   0.23438\n",
      "Epoch  226, Batch_idx  256:  Loss:   3.06677 Validation Accuracy:   0.23438\n",
      "Epoch  227, Batch_idx    0:  Loss:   3.10179 Validation Accuracy:   0.15625\n",
      "Epoch  227, Batch_idx  128:  Loss:   2.97366 Validation Accuracy:   0.17969\n",
      "Epoch  227, Batch_idx  256:  Loss:   2.92899 Validation Accuracy:   0.18750\n",
      "Epoch  228, Batch_idx    0:  Loss:   2.94017 Validation Accuracy:   0.18750\n",
      "Epoch  228, Batch_idx  128:  Loss:   2.83356 Validation Accuracy:   0.18750\n",
      "Epoch  228, Batch_idx  256:  Loss:   2.82780 Validation Accuracy:   0.18750\n",
      "Epoch  229, Batch_idx    0:  Loss:   3.10651 Validation Accuracy:   0.19531\n",
      "Epoch  229, Batch_idx  128:  Loss:   3.10680 Validation Accuracy:   0.17969\n",
      "Epoch  229, Batch_idx  256:  Loss:   3.05726 Validation Accuracy:   0.20312\n",
      "Epoch  230, Batch_idx    0:  Loss:   2.90414 Validation Accuracy:   0.19531\n",
      "Epoch  230, Batch_idx  128:  Loss:   2.86575 Validation Accuracy:   0.20312\n",
      "Epoch  230, Batch_idx  256:  Loss:   2.84743 Validation Accuracy:   0.21875\n",
      "Epoch  231, Batch_idx    0:  Loss:   2.88565 Validation Accuracy:   0.14062\n",
      "Epoch  231, Batch_idx  128:  Loss:   2.84404 Validation Accuracy:   0.14844\n",
      "Epoch  231, Batch_idx  256:  Loss:   2.83246 Validation Accuracy:   0.16406\n",
      "Epoch  232, Batch_idx    0:  Loss:   2.92085 Validation Accuracy:   0.15625\n",
      "Epoch  232, Batch_idx  128:  Loss:   2.88455 Validation Accuracy:   0.16406\n",
      "Epoch  232, Batch_idx  256:  Loss:   2.83726 Validation Accuracy:   0.17188\n",
      "Epoch  233, Batch_idx    0:  Loss:   2.84051 Validation Accuracy:   0.17188\n",
      "Epoch  233, Batch_idx  128:  Loss:   2.79841 Validation Accuracy:   0.18750\n",
      "Epoch  233, Batch_idx  256:  Loss:   2.78326 Validation Accuracy:   0.17188\n",
      "Epoch  234, Batch_idx    0:  Loss:   2.78235 Validation Accuracy:   0.24219\n",
      "Epoch  234, Batch_idx  128:  Loss:   2.79195 Validation Accuracy:   0.23438\n",
      "Epoch  234, Batch_idx  256:  Loss:   2.78095 Validation Accuracy:   0.25000\n",
      "Epoch  235, Batch_idx    0:  Loss:   2.83333 Validation Accuracy:   0.24219\n",
      "Epoch  235, Batch_idx  128:  Loss:   2.81647 Validation Accuracy:   0.25781\n",
      "Epoch  235, Batch_idx  256:  Loss:   2.78860 Validation Accuracy:   0.24219\n",
      "Epoch  236, Batch_idx    0:  Loss:   3.10144 Validation Accuracy:   0.14062\n",
      "Epoch  236, Batch_idx  128:  Loss:   3.15306 Validation Accuracy:   0.14062\n",
      "Epoch  236, Batch_idx  256:  Loss:   3.11813 Validation Accuracy:   0.15625\n",
      "Epoch  237, Batch_idx    0:  Loss:   3.00376 Validation Accuracy:   0.13281\n",
      "Epoch  237, Batch_idx  128:  Loss:   2.93962 Validation Accuracy:   0.15625\n",
      "Epoch  237, Batch_idx  256:  Loss:   2.93313 Validation Accuracy:   0.20312\n",
      "Epoch  238, Batch_idx    0:  Loss:   2.97044 Validation Accuracy:   0.18750\n",
      "Epoch  238, Batch_idx  128:  Loss:   2.94877 Validation Accuracy:   0.17188\n",
      "Epoch  238, Batch_idx  256:  Loss:   2.93543 Validation Accuracy:   0.18750\n",
      "Epoch  239, Batch_idx    0:  Loss:   2.78182 Validation Accuracy:   0.21094\n",
      "Epoch  239, Batch_idx  128:  Loss:   2.73632 Validation Accuracy:   0.21875\n",
      "Epoch  239, Batch_idx  256:  Loss:   2.72824 Validation Accuracy:   0.21875\n",
      "Epoch  240, Batch_idx    0:  Loss:   2.89079 Validation Accuracy:   0.24219\n",
      "Epoch  240, Batch_idx  128:  Loss:   2.85625 Validation Accuracy:   0.25000\n",
      "Epoch  240, Batch_idx  256:  Loss:   2.83432 Validation Accuracy:   0.26562\n",
      "Epoch  241, Batch_idx    0:  Loss:   2.83910 Validation Accuracy:   0.18750\n",
      "Epoch  241, Batch_idx  128:  Loss:   2.80237 Validation Accuracy:   0.21875\n",
      "Epoch  241, Batch_idx  256:  Loss:   2.78973 Validation Accuracy:   0.21094\n",
      "Epoch  242, Batch_idx    0:  Loss:   2.92683 Validation Accuracy:   0.14844\n",
      "Epoch  242, Batch_idx  128:  Loss:   2.93046 Validation Accuracy:   0.17969\n",
      "Epoch  242, Batch_idx  256:  Loss:   2.98051 Validation Accuracy:   0.16406\n",
      "Epoch  243, Batch_idx    0:  Loss:   2.91098 Validation Accuracy:   0.19531\n",
      "Epoch  243, Batch_idx  128:  Loss:   2.82757 Validation Accuracy:   0.21094\n",
      "Epoch  243, Batch_idx  256:  Loss:   2.70398 Validation Accuracy:   0.21094\n",
      "Epoch  244, Batch_idx    0:  Loss:   3.02259 Validation Accuracy:   0.14844\n",
      "Epoch  244, Batch_idx  128:  Loss:   3.04598 Validation Accuracy:   0.16406\n",
      "Epoch  244, Batch_idx  256:  Loss:   2.95836 Validation Accuracy:   0.17188\n",
      "Epoch  245, Batch_idx    0:  Loss:   2.95075 Validation Accuracy:   0.17969\n",
      "Epoch  245, Batch_idx  128:  Loss:   3.00877 Validation Accuracy:   0.15625\n",
      "Epoch  245, Batch_idx  256:  Loss:   3.04271 Validation Accuracy:   0.16406\n",
      "Epoch  246, Batch_idx    0:  Loss:   3.04205 Validation Accuracy:   0.14844\n",
      "Epoch  246, Batch_idx  128:  Loss:   2.95386 Validation Accuracy:   0.14844\n",
      "Epoch  246, Batch_idx  256:  Loss:   2.94190 Validation Accuracy:   0.15625\n",
      "Epoch  247, Batch_idx    0:  Loss:   2.84528 Validation Accuracy:   0.14062\n",
      "Epoch  247, Batch_idx  128:  Loss:   2.88871 Validation Accuracy:   0.14844\n",
      "Epoch  247, Batch_idx  256:  Loss:   2.78102 Validation Accuracy:   0.17969\n",
      "Epoch  248, Batch_idx    0:  Loss:   2.77240 Validation Accuracy:   0.22656\n",
      "Epoch  248, Batch_idx  128:  Loss:   2.88840 Validation Accuracy:   0.22656\n",
      "Epoch  248, Batch_idx  256:  Loss:   2.94269 Validation Accuracy:   0.21094\n",
      "Epoch  249, Batch_idx    0:  Loss:   3.05080 Validation Accuracy:   0.21094\n",
      "Epoch  249, Batch_idx  128:  Loss:   3.03018 Validation Accuracy:   0.20312\n",
      "Epoch  249, Batch_idx  256:  Loss:   2.99526 Validation Accuracy:   0.18750\n",
      "Epoch  250, Batch_idx    0:  Loss:   2.93741 Validation Accuracy:   0.18750\n",
      "Epoch  250, Batch_idx  128:  Loss:   2.88183 Validation Accuracy:   0.19531\n",
      "Epoch  250, Batch_idx  256:  Loss:   2.82968 Validation Accuracy:   0.19531\n",
      "Epoch  251, Batch_idx    0:  Loss:   2.87877 Validation Accuracy:   0.21875\n",
      "Epoch  251, Batch_idx  128:  Loss:   2.87296 Validation Accuracy:   0.22656\n",
      "Epoch  251, Batch_idx  256:  Loss:   2.83337 Validation Accuracy:   0.22656\n",
      "Epoch  252, Batch_idx    0:  Loss:   2.80565 Validation Accuracy:   0.24219\n",
      "Epoch  252, Batch_idx  128:  Loss:   2.80548 Validation Accuracy:   0.24219\n",
      "Epoch  252, Batch_idx  256:  Loss:   2.80864 Validation Accuracy:   0.25000\n",
      "Epoch  253, Batch_idx    0:  Loss:   2.85559 Validation Accuracy:   0.20312\n",
      "Epoch  253, Batch_idx  128:  Loss:   2.82143 Validation Accuracy:   0.19531\n",
      "Epoch  253, Batch_idx  256:  Loss:   2.78600 Validation Accuracy:   0.20312\n",
      "Epoch  254, Batch_idx    0:  Loss:   2.69170 Validation Accuracy:   0.21875\n",
      "Epoch  254, Batch_idx  128:  Loss:   2.66811 Validation Accuracy:   0.23438\n",
      "Epoch  254, Batch_idx  256:  Loss:   2.64115 Validation Accuracy:   0.24219\n",
      "Epoch  255, Batch_idx    0:  Loss:   2.84592 Validation Accuracy:   0.22656\n",
      "Epoch  255, Batch_idx  128:  Loss:   2.84808 Validation Accuracy:   0.21094\n",
      "Epoch  255, Batch_idx  256:  Loss:   2.79043 Validation Accuracy:   0.20312\n",
      "Epoch  256, Batch_idx    0:  Loss:   2.84905 Validation Accuracy:   0.15625\n",
      "Epoch  256, Batch_idx  128:  Loss:   2.84532 Validation Accuracy:   0.17969\n",
      "Epoch  256, Batch_idx  256:  Loss:   2.90309 Validation Accuracy:   0.15625\n",
      "Epoch  257, Batch_idx    0:  Loss:   2.95690 Validation Accuracy:   0.13281\n",
      "Epoch  257, Batch_idx  128:  Loss:   2.98357 Validation Accuracy:   0.12500\n",
      "Epoch  257, Batch_idx  256:  Loss:   2.97880 Validation Accuracy:   0.13281\n",
      "Epoch  258, Batch_idx    0:  Loss:   2.89498 Validation Accuracy:   0.15625\n",
      "Epoch  258, Batch_idx  128:  Loss:   2.92210 Validation Accuracy:   0.16406\n",
      "Epoch  258, Batch_idx  256:  Loss:   2.96915 Validation Accuracy:   0.16406\n",
      "Epoch  259, Batch_idx    0:  Loss:   3.09060 Validation Accuracy:   0.15625\n",
      "Epoch  259, Batch_idx  128:  Loss:   3.02325 Validation Accuracy:   0.17969\n",
      "Epoch  259, Batch_idx  256:  Loss:   3.03016 Validation Accuracy:   0.16406\n",
      "Epoch  260, Batch_idx    0:  Loss:   3.05674 Validation Accuracy:   0.15625\n",
      "Epoch  260, Batch_idx  128:  Loss:   2.95459 Validation Accuracy:   0.16406\n",
      "Epoch  260, Batch_idx  256:  Loss:   2.91725 Validation Accuracy:   0.14844\n",
      "Epoch  261, Batch_idx    0:  Loss:   2.78780 Validation Accuracy:   0.21875\n",
      "Epoch  261, Batch_idx  128:  Loss:   2.74690 Validation Accuracy:   0.22656\n",
      "Epoch  261, Batch_idx  256:  Loss:   2.73786 Validation Accuracy:   0.23438\n",
      "Epoch  262, Batch_idx    0:  Loss:   2.96451 Validation Accuracy:   0.19531\n",
      "Epoch  262, Batch_idx  128:  Loss:   2.96291 Validation Accuracy:   0.20312\n",
      "Epoch  262, Batch_idx  256:  Loss:   2.92255 Validation Accuracy:   0.20312\n",
      "Epoch  263, Batch_idx    0:  Loss:   2.61086 Validation Accuracy:   0.23438\n",
      "Epoch  263, Batch_idx  128:  Loss:   2.58960 Validation Accuracy:   0.21875\n",
      "Epoch  263, Batch_idx  256:  Loss:   2.57797 Validation Accuracy:   0.22656\n",
      "Epoch  264, Batch_idx    0:  Loss:   2.91537 Validation Accuracy:   0.17188\n",
      "Epoch  264, Batch_idx  128:  Loss:   2.88684 Validation Accuracy:   0.17969\n",
      "Epoch  264, Batch_idx  256:  Loss:   2.86942 Validation Accuracy:   0.22656\n",
      "Epoch  265, Batch_idx    0:  Loss:   2.70761 Validation Accuracy:   0.22656\n",
      "Epoch  265, Batch_idx  128:  Loss:   2.68352 Validation Accuracy:   0.22656\n",
      "Epoch  265, Batch_idx  256:  Loss:   2.65633 Validation Accuracy:   0.23438\n",
      "Epoch  266, Batch_idx    0:  Loss:   2.70233 Validation Accuracy:   0.19531\n",
      "Epoch  266, Batch_idx  128:  Loss:   2.68436 Validation Accuracy:   0.20312\n",
      "Epoch  266, Batch_idx  256:  Loss:   2.67070 Validation Accuracy:   0.20312\n",
      "Epoch  267, Batch_idx    0:  Loss:   2.79461 Validation Accuracy:   0.19531\n",
      "Epoch  267, Batch_idx  128:  Loss:   2.79132 Validation Accuracy:   0.18750\n",
      "Epoch  267, Batch_idx  256:  Loss:   2.75678 Validation Accuracy:   0.16406\n",
      "Epoch  268, Batch_idx    0:  Loss:   2.93044 Validation Accuracy:   0.19531\n",
      "Epoch  268, Batch_idx  128:  Loss:   2.93898 Validation Accuracy:   0.21094\n",
      "Epoch  268, Batch_idx  256:  Loss:   2.93019 Validation Accuracy:   0.17188\n",
      "Epoch  269, Batch_idx    0:  Loss:   2.65654 Validation Accuracy:   0.15625\n",
      "Epoch  269, Batch_idx  128:  Loss:   2.61616 Validation Accuracy:   0.16406\n",
      "Epoch  269, Batch_idx  256:  Loss:   2.58995 Validation Accuracy:   0.17188\n",
      "Epoch  270, Batch_idx    0:  Loss:   2.98730 Validation Accuracy:   0.10156\n",
      "Epoch  270, Batch_idx  128:  Loss:   2.93763 Validation Accuracy:   0.16406\n",
      "Epoch  270, Batch_idx  256:  Loss:   2.94038 Validation Accuracy:   0.14844\n",
      "Epoch  271, Batch_idx    0:  Loss:   2.76030 Validation Accuracy:   0.23438\n",
      "Epoch  271, Batch_idx  128:  Loss:   2.75311 Validation Accuracy:   0.23438\n",
      "Epoch  271, Batch_idx  256:  Loss:   2.72129 Validation Accuracy:   0.23438\n",
      "Epoch  272, Batch_idx    0:  Loss:   2.76937 Validation Accuracy:   0.25000\n",
      "Epoch  272, Batch_idx  128:  Loss:   2.75091 Validation Accuracy:   0.25000\n",
      "Epoch  272, Batch_idx  256:  Loss:   2.73847 Validation Accuracy:   0.25000\n",
      "Epoch  273, Batch_idx    0:  Loss:   2.70594 Validation Accuracy:   0.29688\n",
      "Epoch  273, Batch_idx  128:  Loss:   2.65270 Validation Accuracy:   0.28125\n",
      "Epoch  273, Batch_idx  256:  Loss:   2.61137 Validation Accuracy:   0.29688\n",
      "Epoch  274, Batch_idx    0:  Loss:   2.91217 Validation Accuracy:   0.19531\n",
      "Epoch  274, Batch_idx  128:  Loss:   2.88728 Validation Accuracy:   0.19531\n",
      "Epoch  274, Batch_idx  256:  Loss:   2.86990 Validation Accuracy:   0.19531\n",
      "Epoch  275, Batch_idx    0:  Loss:   2.84896 Validation Accuracy:   0.16406\n",
      "Epoch  275, Batch_idx  128:  Loss:   2.84489 Validation Accuracy:   0.16406\n",
      "Epoch  275, Batch_idx  256:  Loss:   2.83270 Validation Accuracy:   0.16406\n",
      "Epoch  276, Batch_idx    0:  Loss:   2.98813 Validation Accuracy:   0.17188\n",
      "Epoch  276, Batch_idx  128:  Loss:   2.98769 Validation Accuracy:   0.17969\n",
      "Epoch  276, Batch_idx  256:  Loss:   2.99450 Validation Accuracy:   0.18750\n",
      "Epoch  277, Batch_idx    0:  Loss:   2.78474 Validation Accuracy:   0.22656\n",
      "Epoch  277, Batch_idx  128:  Loss:   2.75315 Validation Accuracy:   0.25000\n",
      "Epoch  277, Batch_idx  256:  Loss:   2.71665 Validation Accuracy:   0.24219\n",
      "Epoch  278, Batch_idx    0:  Loss:   3.01556 Validation Accuracy:   0.17188\n",
      "Epoch  278, Batch_idx  128:  Loss:   2.99879 Validation Accuracy:   0.19531\n",
      "Epoch  278, Batch_idx  256:  Loss:   2.97196 Validation Accuracy:   0.19531\n",
      "Epoch  279, Batch_idx    0:  Loss:   2.97906 Validation Accuracy:   0.15625\n",
      "Epoch  279, Batch_idx  128:  Loss:   2.95462 Validation Accuracy:   0.16406\n",
      "Epoch  279, Batch_idx  256:  Loss:   2.93216 Validation Accuracy:   0.17969\n",
      "Epoch  280, Batch_idx    0:  Loss:   2.99940 Validation Accuracy:   0.17969\n",
      "Epoch  280, Batch_idx  128:  Loss:   2.97476 Validation Accuracy:   0.15625\n",
      "Epoch  280, Batch_idx  256:  Loss:   2.96943 Validation Accuracy:   0.15625\n",
      "Epoch  281, Batch_idx    0:  Loss:   2.88750 Validation Accuracy:   0.14844\n",
      "Epoch  281, Batch_idx  128:  Loss:   2.85529 Validation Accuracy:   0.15625\n",
      "Epoch  281, Batch_idx  256:  Loss:   2.80234 Validation Accuracy:   0.17969\n",
      "Epoch  282, Batch_idx    0:  Loss:   2.66993 Validation Accuracy:   0.22656\n",
      "Epoch  282, Batch_idx  128:  Loss:   2.63408 Validation Accuracy:   0.26562\n",
      "Epoch  282, Batch_idx  256:  Loss:   2.63036 Validation Accuracy:   0.24219\n",
      "Epoch  283, Batch_idx    0:  Loss:   2.71214 Validation Accuracy:   0.25000\n",
      "Epoch  283, Batch_idx  128:  Loss:   2.71607 Validation Accuracy:   0.24219\n",
      "Epoch  283, Batch_idx  256:  Loss:   2.72168 Validation Accuracy:   0.25000\n",
      "Epoch  284, Batch_idx    0:  Loss:   2.91559 Validation Accuracy:   0.21094\n",
      "Epoch  284, Batch_idx  128:  Loss:   2.86924 Validation Accuracy:   0.21875\n",
      "Epoch  284, Batch_idx  256:  Loss:   2.84399 Validation Accuracy:   0.22656\n",
      "Epoch  285, Batch_idx    0:  Loss:   2.91247 Validation Accuracy:   0.14844\n",
      "Epoch  285, Batch_idx  128:  Loss:   2.91796 Validation Accuracy:   0.14844\n",
      "Epoch  285, Batch_idx  256:  Loss:   2.89152 Validation Accuracy:   0.15625\n",
      "Epoch  286, Batch_idx    0:  Loss:   2.74524 Validation Accuracy:   0.21094\n",
      "Epoch  286, Batch_idx  128:  Loss:   2.77381 Validation Accuracy:   0.21094\n",
      "Epoch  286, Batch_idx  256:  Loss:   2.76322 Validation Accuracy:   0.21094\n",
      "Epoch  287, Batch_idx    0:  Loss:   2.71080 Validation Accuracy:   0.25781\n",
      "Epoch  287, Batch_idx  128:  Loss:   2.68145 Validation Accuracy:   0.24219\n",
      "Epoch  287, Batch_idx  256:  Loss:   2.69470 Validation Accuracy:   0.19531\n",
      "Epoch  288, Batch_idx    0:  Loss:   2.78351 Validation Accuracy:   0.14062\n",
      "Epoch  288, Batch_idx  128:  Loss:   2.77511 Validation Accuracy:   0.14062\n",
      "Epoch  288, Batch_idx  256:  Loss:   2.76153 Validation Accuracy:   0.16406\n",
      "Epoch  289, Batch_idx    0:  Loss:   2.59757 Validation Accuracy:   0.26562\n",
      "Epoch  289, Batch_idx  128:  Loss:   2.56492 Validation Accuracy:   0.27344\n",
      "Epoch  289, Batch_idx  256:  Loss:   2.52099 Validation Accuracy:   0.28125\n",
      "Epoch  290, Batch_idx    0:  Loss:   2.80493 Validation Accuracy:   0.21094\n",
      "Epoch  290, Batch_idx  128:  Loss:   2.78426 Validation Accuracy:   0.21875\n",
      "Epoch  290, Batch_idx  256:  Loss:   2.79044 Validation Accuracy:   0.21875\n",
      "Epoch  291, Batch_idx    0:  Loss:   2.62353 Validation Accuracy:   0.22656\n",
      "Epoch  291, Batch_idx  128:  Loss:   2.56830 Validation Accuracy:   0.24219\n",
      "Epoch  291, Batch_idx  256:  Loss:   2.51785 Validation Accuracy:   0.25781\n",
      "Epoch  292, Batch_idx    0:  Loss:   2.76835 Validation Accuracy:   0.17969\n",
      "Epoch  292, Batch_idx  128:  Loss:   2.77876 Validation Accuracy:   0.20312\n",
      "Epoch  292, Batch_idx  256:  Loss:   2.75415 Validation Accuracy:   0.22656\n",
      "Epoch  293, Batch_idx    0:  Loss:   2.81477 Validation Accuracy:   0.21094\n",
      "Epoch  293, Batch_idx  128:  Loss:   2.79034 Validation Accuracy:   0.21094\n",
      "Epoch  293, Batch_idx  256:  Loss:   2.79052 Validation Accuracy:   0.17969\n",
      "Epoch  294, Batch_idx    0:  Loss:   2.68390 Validation Accuracy:   0.25000\n",
      "Epoch  294, Batch_idx  128:  Loss:   2.67928 Validation Accuracy:   0.24219\n",
      "Epoch  294, Batch_idx  256:  Loss:   2.65809 Validation Accuracy:   0.24219\n",
      "Epoch  295, Batch_idx    0:  Loss:   2.76000 Validation Accuracy:   0.24219\n",
      "Epoch  295, Batch_idx  128:  Loss:   2.75174 Validation Accuracy:   0.24219\n",
      "Epoch  295, Batch_idx  256:  Loss:   2.73899 Validation Accuracy:   0.24219\n",
      "Epoch  296, Batch_idx    0:  Loss:   2.76982 Validation Accuracy:   0.17969\n",
      "Epoch  296, Batch_idx  128:  Loss:   2.75297 Validation Accuracy:   0.18750\n",
      "Epoch  296, Batch_idx  256:  Loss:   2.74489 Validation Accuracy:   0.17969\n",
      "Epoch  297, Batch_idx    0:  Loss:   2.80429 Validation Accuracy:   0.17969\n",
      "Epoch  297, Batch_idx  128:  Loss:   2.73396 Validation Accuracy:   0.18750\n",
      "Epoch  297, Batch_idx  256:  Loss:   2.76371 Validation Accuracy:   0.20312\n",
      "Epoch  298, Batch_idx    0:  Loss:   2.78924 Validation Accuracy:   0.20312\n",
      "Epoch  298, Batch_idx  128:  Loss:   2.72129 Validation Accuracy:   0.21875\n",
      "Epoch  298, Batch_idx  256:  Loss:   2.60657 Validation Accuracy:   0.23438\n",
      "Epoch  299, Batch_idx    0:  Loss:   2.60202 Validation Accuracy:   0.25000\n",
      "Epoch  299, Batch_idx  128:  Loss:   2.68882 Validation Accuracy:   0.25000\n",
      "Epoch  299, Batch_idx  256:  Loss:   2.73075 Validation Accuracy:   0.25781\n",
      "Epoch  300, Batch_idx    0:  Loss:   2.79045 Validation Accuracy:   0.19531\n",
      "Epoch  300, Batch_idx  128:  Loss:   2.74667 Validation Accuracy:   0.17969\n",
      "Epoch  300, Batch_idx  256:  Loss:   2.71748 Validation Accuracy:   0.17188\n",
      "Epoch  301, Batch_idx    0:  Loss:   2.94589 Validation Accuracy:   0.14062\n",
      "Epoch  301, Batch_idx  128:  Loss:   2.91820 Validation Accuracy:   0.15625\n",
      "Epoch  301, Batch_idx  256:  Loss:   2.87556 Validation Accuracy:   0.15625\n",
      "Epoch  302, Batch_idx    0:  Loss:   2.77943 Validation Accuracy:   0.17188\n",
      "Epoch  302, Batch_idx  128:  Loss:   2.76970 Validation Accuracy:   0.16406\n",
      "Epoch  302, Batch_idx  256:  Loss:   2.76658 Validation Accuracy:   0.16406\n",
      "Epoch  303, Batch_idx    0:  Loss:   2.73185 Validation Accuracy:   0.19531\n",
      "Epoch  303, Batch_idx  128:  Loss:   2.72349 Validation Accuracy:   0.21094\n",
      "Epoch  303, Batch_idx  256:  Loss:   2.71119 Validation Accuracy:   0.21094\n",
      "Epoch  304, Batch_idx    0:  Loss:   2.82395 Validation Accuracy:   0.19531\n",
      "Epoch  304, Batch_idx  128:  Loss:   2.80261 Validation Accuracy:   0.19531\n",
      "Epoch  304, Batch_idx  256:  Loss:   2.78920 Validation Accuracy:   0.20312\n",
      "Epoch  305, Batch_idx    0:  Loss:   2.78672 Validation Accuracy:   0.21094\n",
      "Epoch  305, Batch_idx  128:  Loss:   2.77810 Validation Accuracy:   0.20312\n",
      "Epoch  305, Batch_idx  256:  Loss:   2.76759 Validation Accuracy:   0.19531\n",
      "Epoch  306, Batch_idx    0:  Loss:   2.59210 Validation Accuracy:   0.25781\n",
      "Epoch  306, Batch_idx  128:  Loss:   2.57764 Validation Accuracy:   0.25781\n",
      "Epoch  306, Batch_idx  256:  Loss:   2.59073 Validation Accuracy:   0.23438\n",
      "Epoch  307, Batch_idx    0:  Loss:   2.98187 Validation Accuracy:   0.11719\n",
      "Epoch  307, Batch_idx  128:  Loss:   2.94577 Validation Accuracy:   0.11719\n",
      "Epoch  307, Batch_idx  256:  Loss:   2.93326 Validation Accuracy:   0.15625\n",
      "Epoch  308, Batch_idx    0:  Loss:   2.66998 Validation Accuracy:   0.21094\n",
      "Epoch  308, Batch_idx  128:  Loss:   2.64766 Validation Accuracy:   0.20312\n",
      "Epoch  308, Batch_idx  256:  Loss:   2.63448 Validation Accuracy:   0.20312\n",
      "Epoch  309, Batch_idx    0:  Loss:   2.78397 Validation Accuracy:   0.18750\n",
      "Epoch  309, Batch_idx  128:  Loss:   2.77500 Validation Accuracy:   0.19531\n",
      "Epoch  309, Batch_idx  256:  Loss:   2.73957 Validation Accuracy:   0.20312\n",
      "Epoch  310, Batch_idx    0:  Loss:   2.72147 Validation Accuracy:   0.21094\n",
      "Epoch  310, Batch_idx  128:  Loss:   2.71217 Validation Accuracy:   0.21094\n",
      "Epoch  310, Batch_idx  256:  Loss:   2.68452 Validation Accuracy:   0.21875\n",
      "Epoch  311, Batch_idx    0:  Loss:   2.50400 Validation Accuracy:   0.28125\n",
      "Epoch  311, Batch_idx  128:  Loss:   2.50547 Validation Accuracy:   0.27344\n",
      "Epoch  311, Batch_idx  256:  Loss:   2.50565 Validation Accuracy:   0.27344\n",
      "Epoch  312, Batch_idx    0:  Loss:   2.74220 Validation Accuracy:   0.20312\n",
      "Epoch  312, Batch_idx  128:  Loss:   2.70856 Validation Accuracy:   0.17969\n",
      "Epoch  312, Batch_idx  256:  Loss:   2.68001 Validation Accuracy:   0.18750\n",
      "Epoch  313, Batch_idx    0:  Loss:   2.79041 Validation Accuracy:   0.27344\n",
      "Epoch  313, Batch_idx  128:  Loss:   2.80385 Validation Accuracy:   0.26562\n",
      "Epoch  313, Batch_idx  256:  Loss:   2.76975 Validation Accuracy:   0.27344\n",
      "Epoch  314, Batch_idx    0:  Loss:   2.81042 Validation Accuracy:   0.17969\n",
      "Epoch  314, Batch_idx  128:  Loss:   2.78807 Validation Accuracy:   0.21094\n",
      "Epoch  314, Batch_idx  256:  Loss:   2.78621 Validation Accuracy:   0.21875\n",
      "Epoch  315, Batch_idx    0:  Loss:   2.86695 Validation Accuracy:   0.17969\n",
      "Epoch  315, Batch_idx  128:  Loss:   2.85319 Validation Accuracy:   0.17188\n",
      "Epoch  315, Batch_idx  256:  Loss:   2.82996 Validation Accuracy:   0.17969\n",
      "Epoch  316, Batch_idx    0:  Loss:   2.78242 Validation Accuracy:   0.18750\n",
      "Epoch  316, Batch_idx  128:  Loss:   2.75965 Validation Accuracy:   0.19531\n",
      "Epoch  316, Batch_idx  256:  Loss:   2.73300 Validation Accuracy:   0.19531\n",
      "Epoch  317, Batch_idx    0:  Loss:   2.65937 Validation Accuracy:   0.18750\n",
      "Epoch  317, Batch_idx  128:  Loss:   2.64315 Validation Accuracy:   0.17969\n",
      "Epoch  317, Batch_idx  256:  Loss:   2.61809 Validation Accuracy:   0.20312\n",
      "Epoch  318, Batch_idx    0:  Loss:   2.67901 Validation Accuracy:   0.21094\n",
      "Epoch  318, Batch_idx  128:  Loss:   2.66354 Validation Accuracy:   0.24219\n",
      "Epoch  318, Batch_idx  256:  Loss:   2.65812 Validation Accuracy:   0.22656\n",
      "Epoch  319, Batch_idx    0:  Loss:   2.66956 Validation Accuracy:   0.28125\n",
      "Epoch  319, Batch_idx  128:  Loss:   2.65026 Validation Accuracy:   0.28906\n",
      "Epoch  319, Batch_idx  256:  Loss:   2.64726 Validation Accuracy:   0.29688\n",
      "Epoch  320, Batch_idx    0:  Loss:   2.76037 Validation Accuracy:   0.16406\n",
      "Epoch  320, Batch_idx  128:  Loss:   2.73155 Validation Accuracy:   0.15625\n",
      "Epoch  320, Batch_idx  256:  Loss:   2.70465 Validation Accuracy:   0.19531\n",
      "Epoch  321, Batch_idx    0:  Loss:   2.83869 Validation Accuracy:   0.17969\n",
      "Epoch  321, Batch_idx  128:  Loss:   2.85050 Validation Accuracy:   0.17969\n",
      "Epoch  321, Batch_idx  256:  Loss:   2.83945 Validation Accuracy:   0.17969\n",
      "Epoch  322, Batch_idx    0:  Loss:   2.75203 Validation Accuracy:   0.19531\n",
      "Epoch  322, Batch_idx  128:  Loss:   2.71275 Validation Accuracy:   0.20312\n",
      "Epoch  322, Batch_idx  256:  Loss:   2.71613 Validation Accuracy:   0.19531\n",
      "Epoch  323, Batch_idx    0:  Loss:   2.70502 Validation Accuracy:   0.18750\n",
      "Epoch  323, Batch_idx  128:  Loss:   2.65238 Validation Accuracy:   0.18750\n",
      "Epoch  323, Batch_idx  256:  Loss:   2.63376 Validation Accuracy:   0.21094\n",
      "Epoch  324, Batch_idx    0:  Loss:   2.69544 Validation Accuracy:   0.18750\n",
      "Epoch  324, Batch_idx  128:  Loss:   2.68688 Validation Accuracy:   0.24219\n",
      "Epoch  324, Batch_idx  256:  Loss:   2.64577 Validation Accuracy:   0.24219\n",
      "Epoch  325, Batch_idx    0:  Loss:   2.76367 Validation Accuracy:   0.22656\n",
      "Epoch  325, Batch_idx  128:  Loss:   2.73110 Validation Accuracy:   0.23438\n",
      "Epoch  325, Batch_idx  256:  Loss:   2.75184 Validation Accuracy:   0.21094\n",
      "Epoch  326, Batch_idx    0:  Loss:   2.70924 Validation Accuracy:   0.22656\n",
      "Epoch  326, Batch_idx  128:  Loss:   2.65679 Validation Accuracy:   0.25781\n",
      "Epoch  326, Batch_idx  256:  Loss:   2.62807 Validation Accuracy:   0.24219\n",
      "Epoch  327, Batch_idx    0:  Loss:   2.62965 Validation Accuracy:   0.22656\n",
      "Epoch  327, Batch_idx  128:  Loss:   2.63735 Validation Accuracy:   0.23438\n",
      "Epoch  327, Batch_idx  256:  Loss:   2.61925 Validation Accuracy:   0.24219\n",
      "Epoch  328, Batch_idx    0:  Loss:   2.56555 Validation Accuracy:   0.28906\n",
      "Epoch  328, Batch_idx  128:  Loss:   2.53535 Validation Accuracy:   0.28906\n"
     ]
    }
   ],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    #x = neural_net_image_input((32, 32, 3))\n",
    "    #y = neural_net_label_input(10)\n",
    "    #keep_prob = neural_net_keep_prob_input()\n",
    "    \n",
    "    #print(label_batch)\n",
    "    config=tf.ConfigProto(#allow_soft_placement=True,\n",
    "                          log_device_placement=True,\n",
    "                          device_count = {'GPU': 8})\n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    feed_dict={keep_prob:keep_probability,x:feature_batch,y:label_batch}\n",
    "    \n",
    "    #print(feed_dict)\n",
    "\n",
    "    session.run(optimizer,feed_dict=feed_dict)\n",
    "    \n",
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    feed_dict={keep_prob:1.,x:feature_batch,y:label_batch}\n",
    "    \n",
    "    #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "    #optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "    # Calculate batch loss and accuracy\n",
    "    loss = session.run(cost,feed_dict=feed_dict)\n",
    "    \n",
    "    # Should this be done on validation data?\n",
    "    valid_acc = sess.run(accuracy,feed_dict=feed_dict)\n",
    "    print('Loss: {0:9.5f} Validation Accuracy: {1:9.5f}'.format(loss,valid_acc))\n",
    "    \n",
    "def get_next_batch(batches, batch_size = 64):\n",
    "    n_batches = len(batches)//batch_size\n",
    "    for idx in range(0,n_batches,batch_size):\n",
    "        batch = batches[idx:idx+batch_size,:,:,:]\n",
    "        yield [x,y]\n",
    "       \n",
    "# Parameters\n",
    "epochs = 1000  # 1000 @ 128 => 3430 sec / ~1h\n",
    "batch_size = 128\n",
    "keep_probability = 0.90\n",
    "\n",
    "save_model_path = './'\n",
    "\n",
    "import time\n",
    "print('Training...')\n",
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches \n",
    "        n_batches = len(X_train)//batch_size\n",
    "        batch_idx =  ((np.random.random(batch_size)*X_train.shape[0])).astype(int)\n",
    "        for idx in range(0,n_batches,batch_size):\n",
    "            batch_features = X_train[batch_idx,:,:,:]\n",
    "            batch_labels   = y_train[batch_idx]\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>4}, Batch_idx {:>4}:  '.format(epoch + 1, idx), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)\n",
    "    \n",
    "print('Training time : {}'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_model_path = './'\n",
    "n_samples = 10\n",
    "top_n_predictions = 3\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def _load_label_names():\n",
    "    \"\"\"\n",
    "    Load the label names from file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('./signnames.csv')\n",
    "    return df['SignName'].values\n",
    "\n",
    "def display_image_predictions(features, labels, predictions,n_samples,top_n_predictions):\n",
    "    n_classes = 43\n",
    "    label_names = _load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=n_samples, ncols=2)\n",
    "    #fig.tight_layout()\n",
    "    #fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "    fig.suptitle('Softmax Predictions', fontsize=44)\n",
    "    fig.set_size_inches(21, 21)\n",
    "    \n",
    "    n_predictions = 3\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "        \n",
    "        axies[image_i][0].imshow(feature[:,:,3:6])\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])\n",
    "        \n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = X_test, y_test\n",
    "\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        #for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "        n_batches = len(X_test)//batch_size\n",
    "        for idx in range(0,n_batches,batch_size):\n",
    "            train_feature_batch = X_test[idx:idx+batch_size,:,:,:]\n",
    "            train_label_batch   = y_test[idx:idx+batch_size]\n",
    "            \n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions,n_samples,top_n_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For each of the new images, print out the model's softmax probabilities to show the **certainty** of the model's predictions (limit the output to the top 5 probabilities for each image). [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. \n",
    "\n",
    "The example below demonstrates how tf.nn.top_k can be used to find the top k predictions for each image.\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example. The values in the array represent predictions. The array contains softmax probabilities for five candidate images with six possible classes. `tk.nn.top_k` is used to choose the three classes with the highest probability:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 4: Visualize the Neural Network's State with Test Images\n",
    "\n",
    " This Section is not required to complete but acts as an additional excersise for understaning the output of a neural network's weights. While neural networks can be a great learning device they are often referred to as a black box. We can understand what the weights of a neural network look like better by plotting their feature maps. After successfully training your neural network you can see what it's feature maps look like by plotting the output of the network's weight layers in response to a test stimuli image. From these plotted feature maps, it's possible to see what characteristics of an image the network finds interesting. For a sign, maybe the inner network feature maps react with high activation to the sign's boundary outline or to the contrast in the sign's painted symbol.\n",
    "\n",
    " Provided for you below is the function code that allows you to get the visualization output of any tensorflow weight layer you want. The inputs to the function should be a stimuli image, one used during training or a new one you provided, and then the tensorflow variable name that represents the layer's state during the training process, for instance if you wanted to see what the [LeNet lab's](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) feature maps looked like for it's second convolutional layer you could enter conv2 as the tf_activation variable.\n",
    "\n",
    "For an example of what feature map outputs look like, check out NVIDIA's results in their paper [End-to-End Deep Learning for Self-Driving Cars](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) in the section Visualization of internal CNN State. NVIDIA was able to show that their network's inner weights had high activations to road boundary lines by comparing feature maps from an image with a clear path to one without. Try experimenting with a similar test to show that your trained network's weights are looking for interesting features, whether it's looking at differences in feature maps from images with or without a sign, or even what feature maps look like in a trained network vs a completely untrained one on the same sign image.\n",
    "\n",
    "<figure>\n",
    " <img src=\"visualize_cnn.png\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output should look something like this (above)</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it maybe having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 9\n",
    "\n",
    "Discuss how you used the visual output of your trained network's feature maps to show that it had learned to look for interesting characteristics in traffic sign images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Project Writeup\n",
    "\n",
    "Once you have completed the code implementation, document your results in a project writeup using this [template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) as a guide. The writeup can be in a markdown or pdf file. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
